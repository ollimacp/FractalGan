{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacial boxcount algorithm and translation into convolutional neural network\n",
    "\n",
    "Ole Peters\n",
    "    \n",
    "## 1 Abstract\n",
    "\n",
    "This paper contains the postulation of a spacial boxcount algorithm, which characterizes any incoming 2D array spacially by indicators for topological complexity and spacial heterogeneity at different scales. This characterization allows spacial similarity search or sorting capability, edge detection with userspecified scaling and statistical analysis of input datasets. The algorithm can handle any kind of data able to be represented in a 2 dimensional array. \n",
    "By training a convolutional neural network to mimic the cpu driven function, the process could speedup by a huge factor utilizing the parallel capabilities of a graphics card.\n",
    "\n",
    "## 2 Introduction\n",
    "\n",
    "The daily advances in machine learning establish technological advances in almost any area of research. \n",
    "Convolutional neural networks gained a lot of traction, outperforming linear models and even recurrent models in timeseries forecasting. They often are used in object detection and are computationally intensive tasks.\n",
    "\n",
    "Box counting like [1] is a method to analyze data by breaking the input array into boxes at different scales and counting every filled box indicating the spacial complexity for each scaling by the chosen the boxsize. An animation of this process is shown in figure 1.\n",
    "\n",
    "![BoxcountingURL](https://upload.wikimedia.org/wikipedia/commons/5/53/Fixedstack.gif \"Fixed grid scans\")\n",
    "Figure 1: Fixed grid gliding box scanning animation\n",
    "Source: <https://commons.wikimedia.org/wiki/File:Fixedstack.gif>\n",
    "\n",
    "Lacunarity is a mathematical discription for spacial heterogeneity at a chosen scale [2].\n",
    "With the boxcount and lacunarity, which depends on the boxsize, comparisons between different samples of the same data type can be made. By comparing these samples, similar structures can be found and sorted by spacial complexity and heterogeneity. This enables characterization of continuously distributed data.\n",
    "\n",
    "![LacunarityUrl](https://upload.wikimedia.org/wikipedia/commons/3/31/Rotational_Invariance_Example.gif \"lacunarity\")\n",
    "Figure 2 : Lacunaritys or spacial heterogeneity of three different patterns\n",
    "Source: https://commons.wikimedia.org/wiki/File:Rotational_Invariance_Example.gif\n",
    "\n",
    "\n",
    "The spacial resolution of the boxcount algorithm can be achieved by chunking the picture into boxsize specified large areas, where within the boxcounting is executed resulting in a 2D array scaled inverse by the boxsize. These arrays represent the spacially distributed topological complexity and heterogeneity at a chosen scale. The counted boxes reveal different topological features and the lacunarity indicates defects in pattern respectively to their boxsizes. The boxsizes 2, 4, 8 and 16 were used, resulting in arrays with corresponding areas of 1/2, 1/4, 1/8, 1/16 of the original image size.\n",
    "\n",
    "The example dataset consists of electron microscope images of femtosecond laser machined metal surfaces like the example shown in figure 3. These micro- and nanostructures are laser induced periodic surface structures, which are also known as LIPSS and can achieve drastic alterations on surface wettability.\n",
    "Also a few images of hydrophobic leaf surfaces are contained in the dataset.\n",
    "\n",
    "The dataset can be downloaded at: <https://drive.google.com/file/d/1sLc8Uk61W_4TTtmRk4x6_5cOiWq7IeOT/view?usp=sharing>\n",
    "\n",
    "![image info](https://raw.githubusercontent.com/ollimacp/spacial-boxcounting-cpu-gpu/main/0Data/MISC/17_3_Rand.bmp)\n",
    "\n",
    "Figure 3: Sample photo of a femtosecond laser machined metal surface with various surface features\n",
    "\n",
    "In Figure 4 an output of the program has been generated, which results in pictures composed of boxcount ratios and lacunaritys at the chosen boxsize.\n",
    "Scale dependent features emerge at different boxsizes. The boxcount array indicates topological complexity, while contrast in the lacunarity array can distinguish spacial heterogeneous from homogenous surface featuers. \n",
    "\n",
    "![image info](https://raw.githubusercontent.com/ollimacp/spacial-boxcounting-cpu-gpu/main/0Data/generated_imgs/17_3_Rand.png)\n",
    "\n",
    "Figure 4: Generated picture of resulting boxcount and lacunarity arrays with the boxsizes 2,4,8,16  reveal different subpatterns derived from the surface structure.\n",
    "\n",
    "The concept of scanning arrays to count boxes or to perform a computation, like calculating the lacunarity, compared to the concept of convolutional neural networks with their kernel sized, stride moving convolution layers seem very similar. So a convolutional neural network could learn this task utilizing parallel processing power.\n",
    "\n",
    "![Convolution_Animation](https://upload.wikimedia.org/wikipedia/commons/1/19/2D_Convolution_Animation.gif \"Convolution Animation\")\n",
    "\n",
    "Figure 5: Animation of a convolution operation in a convolutional neural network.   \n",
    "Source: https://commons.wikimedia.org/wiki/File:2D_Convolution_Animation.gif\n",
    "\n",
    "\n",
    "## 3 Experimental Setup and Methods\n",
    "\n",
    "In this paper a boxcount algorithm is proposed which can characterize data spacially in topological complexity and heterogeneity at a chosen scale.\n",
    "\n",
    "This algorithm enables characterizing, sorting and searching for spacial similarity for any kind of input data. Here pictures of different topologies formed in a process of laser induced periodic surface structures(LIPSS) were used to demonstrate the algorithms capability.\n",
    "\n",
    "\n",
    "### 3.1 Prerequisites\n",
    "Python3 (preferred version <=3.8) is used to execute this code. By using version 3.8, the essential package named numba is not available at date of publication.\n",
    "The following external packages can be installed with the module manager pip, which is already included in python.\n",
    "To handle n-dimensional array data efficiently the numpy module is necessary and many other imports depend on numpy to function correctly.\n",
    "The module pillow allows to load pictures in many different formats and handles image manipulation, like cropping and accessing individual channels, like RGB, RYB.\n",
    "To visualize the progress during tasks, the module tqdm displays a progressbar with other statistics by a modified for loop. Matplotlib is used to make graphs and plots from arrays, data or pictures.\n",
    "In case of high level path accessing capabilities pathlib is needed and for storing and loading arbitrary data pickel is used.\n",
    "While developing an algorithm with python due its simple code structure is rather fast, executing performance compared to other languages like c,c++,c# or assembler is terrible. In this case the numba jit compiler compiles decorated python functions in c code which speeds up process intensive tasks by a huge margin.\n",
    "\n",
    "For the machine learning part pytorch in combination of a graphics card and the necessary cuda package is used to speed up training time. For testing and executing a model just the cpu and ram is needed, but the gpu can also be utilized to speed up computation and is neccesary due to long training times. To preprocess incoming data the scykit-learn package is utilized. For hyperparameter optimization the package hyperopt was chosen to suggest values for various variables/hyperparameters to achieve a minimized loss during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\ole peters\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (22.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ole peters\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.21.5)\n",
      "Requirement already satisfied: pillow in c:\\users\\ole peters\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (9.0.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ole peters\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.62.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ole peters\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: pathlib in c:\\users\\ole peters\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ole peters\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\ole peters\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ole peters\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ole peters\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ole peters\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ole peters\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (4.29.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ole peters\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ole peters\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: numba in c:\\users\\ole peters\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.55.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ole peters\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from numba) (60.9.1)\n",
      "Requirement already satisfied: numpy<1.22,>=1.18 in c:\\users\\ole peters\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from numba) (1.21.5)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\users\\ole peters\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from numba) (0.38.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nCode package documentation:\\n[3] https://numpy.org/doc/1.20/\\n[4] https://tqdm.github.io/docs/tqdm/\\n[5] https://matplotlib.org/3.3.3/contents.html\\n[6] https://docs.python.org/3/library/pathlib.html\\n[7] https://numba.readthedocs.io/en/stable/user/jit.html\\n[8] https://pytorch.org/docs/stable/nn.init.html\\n[9] https://sklearn.org/documentation.html\\n[10] http://hyperopt.github.io/hyperopt/\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ATTENTION: This cell has only to be executed, if you want to install the necessary packages.\n",
    "#           So just execute, if you want to install the package.\n",
    "\n",
    "#Update Python Package Manager pip\n",
    "!python3 -m  pip install --upgrade pip --user\n",
    "#Prequesits linux via Python Package installer pip:\n",
    "#Python version 3 has to be installedon the system to be able to execute the code \n",
    "!pip3 install numpy pillow tqdm matplotlib pathlib\n",
    "\n",
    "\n",
    "#ATTENTION if you use python3.9 numba will not work currently, so comment every line with 'numba' and 'jit' out\n",
    "!pip3 install numba\n",
    "\n",
    "# install pytorch with gpu support for local cuda version 11.0... modify as needed \n",
    "#  [15] https://varhowto.com/install-pytorch-1-6-0/\n",
    "'''\n",
    "ATTENTION: FOR CUDA-GPU VERSION USE THE NEXT LINE, IF CPU IS WANTED, \n",
    "JUST COMMENT THE NEXT OUT AND  UNCOMMENT THE CPU INSTALL COMMAND in 3 LINES\n",
    "'''\n",
    "#!pip3 install torch===1.7.0+cu110 torchvision===0.8.1+cu110 torchaudio===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#  if there is no CUDA capable GPU just install cpu version\n",
    "\n",
    "#!pip3 install torch==1.7.1+cpu torchvision==0.8.2+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
    "    \n",
    "# when this versions doesn't work, try some other versions from the previous link\n",
    "\n",
    "!pip3 install sklearn hyperopt # install sci-kit learn and hyperoptimization libary\n",
    "\n",
    "'''\n",
    "Code package documentation:\n",
    "[3] https://numpy.org/doc/1.20/\n",
    "[4] https://tqdm.github.io/docs/tqdm/\n",
    "[5] https://matplotlib.org/3.3.3/contents.html\n",
    "[6] https://docs.python.org/3/library/pathlib.html\n",
    "[7] https://numba.readthedocs.io/en/stable/user/jit.html\n",
    "[8] https://pytorch.org/docs/stable/nn.init.html\n",
    "[9] https://sklearn.org/documentation.html\n",
    "[10] http://hyperopt.github.io/hyperopt/\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Imports\n",
    "\n",
    "To execute the code a few necessary python modules and libraries need to be loaded. The imported modules range from external libraries, which were discussed in 3.1 to internal modules like os and time. Also linecache and sys are used to generate a helper function to print information from thrown exceptions, executed in a \"try and except\" syntax. \n",
    "Matplotlib is used to display arrays as pictures with the specified helper function executed with the corresponding array, title and colormap. Documentations of all used python libraries are found in chapter 6 at [3-14]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports------------------------------------------------------------------------------------------\n",
    "import os              #Operating Sytem Module for getting paths, commands, etc...\n",
    "from os import listdir #class for listing files in a directory\n",
    "import time            #for time measurement\n",
    "import pickle          #for loading/saving Data\n",
    "from PIL import Image  #Imagemanipulation via pillow image module\n",
    "\n",
    "import pathlib              #Import pathlib to create a link to the directory where the file is at.\n",
    "#just has to be specified in jupyter, if executed via the terminal __file__ is been found\n",
    "__file__ = 'Spacial boxcount algorithm CPU and GPU.ipynb'    # Just use this when  __file__ is not been found\n",
    "FileParentPath = str(pathlib.Path(__file__).parent.absolute()) # Variable for path, where this file is in!\n",
    "'''\n",
    "Code package documentation:\n",
    "[11] https://docs.python.org/3/library/os.html\n",
    "[12] https://docs.python.org/3/library/pickle.html\n",
    "[13] https://docs.python.org/3/library/time.html\n",
    "[14] https://pillow.readthedocs.io/en/stable/\n",
    "'''\n",
    "#Math module imports----------------------------\n",
    "import numpy as np     # Python package for numeric computation\n",
    "\n",
    "#Visualizing\n",
    "import matplotlib.pyplot as plt # Python plotting libary for visualizing graphs, data and images\n",
    "import matplotlib.image as img \n",
    "#%matplotlib inline  #just used in jupyter, if the plots are not shown\n",
    "from tqdm import tqdm  # Progressbar\n",
    "\n",
    "#Importing nessecary modules for creating machine learning networks, such as \n",
    "import torch                                    # Pytorch machine learning framework.\n",
    "import torch.nn as nn                           # neural network components\n",
    "import torch.nn.functional as F                 # activation functions\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim                      #optimizer here adam will be used\n",
    "\n",
    "#Preprocessing libary for scaling and normalzing nD-arrays\n",
    "import sklearn.preprocessing as preprocessing\n",
    "\n",
    "#Hyperparameteroptimization for training network with coustom parameters\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials  #hyperoptimization libary\n",
    "\n",
    "\n",
    "#If something goes wrong just use the PrintExeption() function to get all neccesary data\n",
    "#Sourced from: [16] https://stackoverflow.com/questions/14519177/python-exception-handling-line-number#20264059\n",
    "import linecache\n",
    "import sys\n",
    "\n",
    "def PrintException():\n",
    "    exc_type, exc_obj, tb = sys.exc_info()\n",
    "    f = tb.tb_frame\n",
    "    lineno = tb.tb_lineno\n",
    "    filename = f.f_code.co_filename\n",
    "    linecache.checkcache(filename)\n",
    "    line = linecache.getline(filename, lineno, f.f_globals)\n",
    "    print('EXCEPTION IN ({}, LINE {} \"{}\"): {}'.format(filename, lineno, line.strip(), exc_obj))\n",
    "    \n",
    "    \n",
    "#Helper-function to show any np.array as a picture with a chosen title and a colormapping \n",
    "def showNPArrayAsImage(np2ddArray, title, colormap):\n",
    "    plt.figure()                    #Init figure\n",
    "    plt.imshow(np2ddArray,          #Gererate a picture from np.array and add to figure\n",
    "            interpolation='none',\n",
    "            cmap = colormap)\n",
    "    plt.title(title)                #Add title to figure\n",
    "    plt.show(block=False)           #Show array as picture on screen, but dont block the programm to continue.\n",
    "\n",
    "\n",
    "verbosity = False   # False: no text displayed ;  True: potentially useful printouts are shown for info/bugfixing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Spacial Boxcount CPU algorithm\n",
    "\n",
    "\n",
    "### 3.3.1 Function: Z-boxcounting - Intrinsic value boxcounting\n",
    "\n",
    "The z-boxcounting is derived from the original boxcount concept [1]. The function is executed with a 2D, picture like array with intrinsic values ranging depending on the given data format. The maximum value of the intrinsic dimensionality depends on the numeric encoding of the data. The maximum intrinsic value for hexcode is 15, for a normal 8-bit grayscale image it is 255, while a high dynamic range picture with 12 bit has a value of 4095. \n",
    "The z-boxcounting gets a chunk of the original picture or array so x and y borders are defined externally.\n",
    "The input array is now seen as a volume with lateral borders (x, y) and the height defined by the maximum intrinsic value into the z direction, hence the name z-boxcounting. The algorithm counts the sum of all, at least partially, filled boxes in a fixed grid scan scaled by the specified boxsize. The actual count ranges inversely proportional to its chosen boxsize and can get really high with a 2³ box. To get the same value range for each boxsize, the counted boxes are divided by the total number of boxes resulting in the boxcount ratio. This ratio ranges from zero, with no counted boxes, to one, describing that all possible boxes were counted.\n",
    "\n",
    "![image info](https://raw.githubusercontent.com/ollimacp/spacial-boxcounting-cpu-gpu/main/0Data/Document_images/lacunarity_formula.png)\n",
    "Figure 6: Formula to calculate the lacunarity, given the standard deviation sigma and mean µ.  \n",
    "\n",
    "At the same time a list of counted values is recorded per box, so the lacunarity, or spacial heterogeneity can be calculated. The lacunarity is calculated by taking the standard deviation σ of the list of counted values for each box and is devided by the mean µ of it [2]. So that all output lacunaritys are positive the former term is taken to the power of 2. This results in a property where lacunaritys against zero describing a homogeneous structures and by increasing lacunarity spacial heterogeneity emerges.\n",
    "\n",
    "The input spacial data chunk ranging in x,y and intrinsic value will be transformed into statistical data. This statistical data can be compared to other boxcounted structures.\n",
    "\n",
    "\n",
    "\n",
    "![BoxcountingURL](https://upload.wikimedia.org/wikipedia/commons/5/53/Fixedstack.gif \"Fixed grid scans\")\n",
    "Figure 7: Fixed grid scanning animation\n",
    "Source: https://commons.wikimedia.org/wiki/File:Fixedstack.gif\n",
    "\n",
    "\n",
    "### 3.3.2 Function: Spacial boxcounting\n",
    "\n",
    "The spacial boxcounting is cropping the input picture, or 2D numpy array to the specified box boundries in x and y respectively. This cropped box represents the gliding box, which is scanning in a fixed grid manner iterativly over the picture or array and determines the counted boxes and the lacunarity at a given coordinate in the picture by accessing the z-boxcounting function. The boxsize of is equal to the stride resulting in a fixed grid with no overlap slicing the input array into chunks. The z-boxcounting is applied to each chunk and returns the boxcount ratio and lacunarity, which forms a boxcount and lacunarity array individually according to the spacial location in the original image and is scaled down by the inverse of the boxsize. \n",
    "\n",
    "\n",
    "### 3.3.3 C-compiler and multithreading for optimizing computation time\n",
    "\n",
    "#### 3.3.3.1 C-compiler jit from numba\n",
    "To gain huge speedup compared to the standard python compiler a different compiler can be used just by decorating the specified function with a \"@jit(nopython=True)\" decorator. The compiling of the c-code results in an increased process overhead, but a significant speedup in computation. For time comparison, go to section 4.2 in results and discussion. The numba compiler can not translate every arbitrary python function from every module, so the code has to be syntax conform by using simple python or numpy functions to achieve proper results.\n",
    "\n",
    "\n",
    "#### 3.3.3.2. Multithreading\n",
    "The boxcounting is a sequential task, which has to be rerun for each chosen boxsize and it results in four parallelizable tasks. This parallelization can be utilized by the threading module and by defining a thread-class, which is able to return a value, however this is not achievable with the threading base-class.\n",
    "Each thread with it's chosen boxsize is started, executed and after the completion it's rejoined with the main thread to create a dictionary with all spacial boxcount- and lacunarity-arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbosity = False   # False: no text displayed ;  True: potentially useful printouts are shown for info/bugfixing.\n",
    "\n",
    "#Numba translates Python functions to optemized machine code at runtime and results in significant speedups\n",
    "from numba import jit\n",
    "\n",
    "#If you want to compare the jit-compiler to the standard python interpreter just un/comment all @jit(... lines.\n",
    "@jit(nopython= True,nogil=True) # Set \"nopython\" mode for best performance, equivalent to @njit\n",
    "def Z_boxcount(GlidingBox, boxsize,MaxValue):\n",
    "    continualIndexes = GlidingBox/boxsize    # tells in which boxindex the given value is in a continual way\n",
    "    Boxindexes = np.floor(continualIndexes)  # Round all boxindexes down to ints to get the boxindex of each value in the gliding box \n",
    "    \n",
    "    # If a value is in a given box, the boxcount increases by 1, but no further, when another  value is in the same box\n",
    "    unique_Boxes = np.unique(Boxindexes)    # numpy helper function to create a list of the unique values by discarding doubles \n",
    "    counted_Boxes = len(unique_Boxes)       # the lenght of the list of all unique indexes are all unique counted boxes within the gliding box and the z-range\n",
    "\n",
    "    if verbosity == True:\n",
    "        print(continualIndexes)\n",
    "        print(\"Boxindex\",Boxindexes)\n",
    "        print(\"counted_Boxes\",counted_Boxes)\n",
    "    \n",
    "    #CREATE  List of SumPixInBox for all boxes to calc lacunarity\n",
    "    InitalEntry = [0.0]\n",
    "    SumPixInBox = np.array(InitalEntry)\n",
    "\n",
    "    #For tiny boxes it can be process consuming\n",
    "    #for every unique counted boxindex in the list of all unique boxindexes\n",
    "    for unique_BoxIndex in unique_Boxes:\n",
    "        #set element-wise to True, when a boxindex is equal to the chosen unique boxindex\n",
    "        ElementsCountedTRUTHTABLE = Boxindexes == unique_BoxIndex\n",
    "        #the sum of the True elements represent the count of datapoints/pixel/voxel within the chosen box\n",
    "        ElementsCounted = np.sum(ElementsCountedTRUTHTABLE)\n",
    "        #Append the list of ElementsCounted to the list of all Elementcounted-lists to calc lacunarity later\n",
    "        SumPixInBox = np.append(SumPixInBox, ElementsCounted)\n",
    "        \n",
    "        if verbosity == True:\n",
    "            print(\"unique_BoxIndex\",unique_BoxIndex)\n",
    "            print(\"ElementsCountedTRUTHTABLE\",ElementsCountedTRUTHTABLE)\n",
    "            print(\"ElementsCounted\",ElementsCounted)\n",
    "\n",
    "            \n",
    "    # Because the lacunarity is calculated with the standard deviation of all elementscounted\n",
    "    # and the not counted boxes have a value of 0 boxes counted in this box\n",
    "    # we have to calc the number of empty boxes by subtracting all counted boxes from the total amount of possible boxes\n",
    "    Max_Num_Boxes = int(MaxValue/ boxsize)\n",
    "    Num_empty_Boxes = Max_Num_Boxes- counted_Boxes\n",
    "    \n",
    "    if Num_empty_Boxes <1:      \n",
    "        pass\n",
    "        # if there is are no empty boxes, just pass\n",
    "    else:\n",
    "        EmptyBoxes = np.zeros(Num_empty_Boxes)\n",
    "        SumPixInBox = np.append(SumPixInBox, EmptyBoxes)\n",
    "    # calcs the mean of the list of all counted datapoints/pixel/voxel within chosen boxes and then...\n",
    "    mean = np.mean(SumPixInBox)\t # ...calcs the standard deviation of the same\n",
    "    standardDeviation = np.std(SumPixInBox)\n",
    "    #The lacunarity or spacial heterogeneity  = (standard deviation/mean)^2 \n",
    "    Lacunarity=np.power(standardDeviation/mean,2)\n",
    "\n",
    "    if verbosity == True:\n",
    "        print(\"Max_Num_Boxes\",Max_Num_Boxes)\n",
    "        print(\"Num_empty_Boxes\",Num_empty_Boxes)\n",
    "        print(\"mean\",mean)\n",
    "        print(\"standardDeviation\",standardDeviation)\n",
    "        print(\"die Lacunarity ist\", Lacunarity)\n",
    "\n",
    "    return counted_Boxes, Lacunarity\n",
    "\n",
    "\n",
    "\n",
    "@jit(nopython= True, nogil=False) #False,forceobj=True) # Set \"nopython\" mode for best performance, equivalent to @njit\n",
    "def spacialBoxcount(npOutputFile, iteration,MaxValue):\n",
    "    '''\n",
    "    This function takes in a 2D np.array the iteration which determins the boxsize\n",
    "    and the maximum possible value to set up the value range. 8-Bit -> 256, hexadez ->16\n",
    "    \n",
    "    The function returns a 2 channel-2d array containing the spacial boxcount ratio and the\n",
    "    spacial lacunarity scaled down in size by 1/Boxsize[iteration]\n",
    "    '''\n",
    "    Boxsize=[2,4,8,16,32,64,128,256,512,1024]  #All boxsizes\n",
    "    boxsize = Boxsize[iteration]               #specified boxsize\n",
    "\n",
    "    #Init counting box at x=0,y=0 und z=0\n",
    "    BoxBoundriesX = np.array([0,Boxsize[iteration]])\n",
    "    BoxBoundriesY = np.array([0,Boxsize[iteration]])\n",
    "\n",
    "    Boxcount = 0\n",
    "    YRange, XRange  = npOutputFile.shape\n",
    "    \n",
    "    #The maximum index of box with given boxsize in x and y direction\n",
    "    maxIndexY = YRange / boxsize \n",
    "    maxIndexY = int(maxIndexY)+1\n",
    "\n",
    "    maxIndexX = XRange / boxsize \n",
    "    maxIndexX = int(maxIndexX)+1\n",
    "\n",
    "    \n",
    "    \n",
    "    if verbosity == True:\n",
    "        print( \"XRange, YRange\", XRange, YRange)\n",
    "        print(\"maxIndexX: \",maxIndexX,\"maxIndexY: \",maxIndexY)\n",
    "\n",
    "    #Initialize the BoxcountRatio_map and spacial_lacunarity_map with zeros in correct shape\n",
    "    BoxCountR_map = np.zeros((maxIndexY,maxIndexX))\n",
    "    spa_Lac_map = np.zeros((maxIndexY,maxIndexX))\n",
    "\n",
    "\n",
    "    while BoxBoundriesY[1]<=YRange:\n",
    "\n",
    "        while BoxBoundriesX[1]<=XRange:\n",
    "            #Set up Boxindex with boxsize\n",
    "            indexY = int(BoxBoundriesY[0]/boxsize)\n",
    "            indexX = int(BoxBoundriesX[0]/boxsize)\n",
    "            \n",
    "            #Define Gliding box with Boundries ... for ex.  Boxsize 4  -> Boxboundries [0,4],[4,8] -> geht auf für n² wie in bildern etc und stitching is möglich\n",
    "            GlidingBox = npOutputFile[BoxBoundriesY[0]:BoxBoundriesY[1],BoxBoundriesX[0]:BoxBoundriesX[1]] \n",
    "\n",
    "            counted_Boxes, Lacunarity = Z_boxcount(GlidingBox, boxsize, MaxValue)\n",
    "            \n",
    "            #Despite counting the Boxes like in the original algorithm, the counts are normalized from 0...1\n",
    "            #0 means there was nothing counted inside  and 1 means every possible box is filled in\n",
    "            Max_Num_Boxes = int(MaxValue/ boxsize)\n",
    "            counted_Box_Ratio = counted_Boxes / Max_Num_Boxes \n",
    "            \n",
    "            BoxCountR_map[indexY,indexX] = counted_Box_Ratio\n",
    "            spa_Lac_map[indexY,indexX] = Lacunarity\n",
    "\n",
    "            #move box into x direction, while boxboundriesx are <= xrange\n",
    "            BoxBoundriesX[0]+=Boxsize[iteration]\n",
    "            BoxBoundriesX[1]+=Boxsize[iteration]\n",
    "            \n",
    "            if verbosity == True:\n",
    "                print(\"indexX: \",indexX)\n",
    "                print(\"indexY: \",indexY)\n",
    "                print(\"BoxBoundriesX: \",BoxBoundriesX)\n",
    "                print(\"BoxBoundriesY: \",BoxBoundriesY)\n",
    "                print(\"GlidingBox: \", GlidingBox)\n",
    "                print(\"counted_Boxes, Lacunarity.: \",counted_Boxes, Lacunarity)\n",
    "\n",
    "                \n",
    "        #By exit inner while loop, box has reached end of x axis in array, so reset boxboundriesX to start\n",
    "        BoxBoundriesX[0]=0\n",
    "        BoxBoundriesX[1]=Boxsize[iteration]\n",
    "        #and increase the counting box in y direction by a boxsize to scan the next line\n",
    "        BoxBoundriesY[0]+=Boxsize[iteration]\n",
    "        BoxBoundriesY[1]+=Boxsize[iteration]\n",
    "\n",
    "    BoxCountR_SpacialLac_map = [BoxCountR_map, spa_Lac_map]\n",
    "    \n",
    "    if verbosity == True:\n",
    "        print(BoxCountR_map)\n",
    "        print(spa_Lac_map)\n",
    "        print(\"Iteration \", iteration, \"calculation done\")\n",
    "\n",
    "    return BoxCountR_SpacialLac_map\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def MultithreadBoxcount(npOutputFile):\n",
    "    \n",
    "    '''\n",
    "    To gain another speedup in the sequential generated output, multi threading is used\n",
    "    to calculate the spacial Boxcountratios/lacunaritys for each boxsize in a own thread.\n",
    "    \n",
    "    '''\n",
    "    #MULTICORE APROACH\n",
    "    #print(\"Beginn Multithread Boxcount Lacunarity feature extraction\")\n",
    "    BoxsizeDict={\"2\":0 ,\"4\":1,\"8\":2,\"16\":3,\"32\":4,\"64\":5,\"128\":6,\"256\":7,\"512\":8,\"1024\":9}\n",
    "\n",
    "    #Cut to lenght\n",
    "    Height , width = npOutputFile.shape\n",
    "    Height , width = int(Height) , int(width) \n",
    "    BaseITERMinVal = min(16,Height , width  )\n",
    "    BaseIteration = BoxsizeDict[str(int(BaseITERMinVal))] #without 0 there are 1 more processes \n",
    "    maxiteration =  BaseIteration +1    # to calc Lacunarity there have to be more than just one box into the z direction\n",
    "    \n",
    "    #source: [17]  https://stackoverflow.com/questions/6893968/how-to-get-the-return-value-from-a-thread-in-python\n",
    "\n",
    "    def BoxcountBoxsizeWorker(npOutputFile, iteration):\n",
    "        maxvalue = 256  # cause zheight is 0...255: 8-bit grayscale picture\n",
    "        #adjust for every specific input\n",
    "        BoxCountR_SpacialLac_map = spacialBoxcount(npOutputFile, iteration,maxvalue )     \n",
    "        \n",
    "        return BoxCountR_SpacialLac_map\n",
    "\n",
    "    from threading import Thread\n",
    "    \n",
    "    #Create thread-class with ability to return a value, which is not possible in threading\n",
    "    class ThreadWithReturnValue(Thread):\n",
    "        def __init__(self, group=None, target=None, name=None,\n",
    "                    args=(), kwargs={}, Verbose=None):\n",
    "            Thread.__init__(self, group, target, name, args, kwargs)\n",
    "            self._return = None\n",
    "        def run(self):\n",
    "            #print(type(self._target))\n",
    "            if self._target is not None:\n",
    "                self._return = self._target(*self._args,\n",
    "                                                    **self._kwargs)\n",
    "        def join(self, *args):\n",
    "            Thread.join(self, *args)\n",
    "            return self._return\n",
    "\n",
    "\n",
    "    #Init number of needed threads\n",
    "    threads = [None] * maxiteration      \n",
    "    if verbosity: print(\"Generate \",maxiteration,\"threads\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for i in range(len(threads)):\n",
    "        threads[i] = ThreadWithReturnValue(target=BoxcountBoxsizeWorker, args=(npOutputFile, i))\n",
    "        threads[i].start()\n",
    "        if verbosity == True:\n",
    "            print(\"thread \",i+1,\" has started\")\n",
    "\n",
    "    BoxCountR_SpacialLac_map_Dict = {\"iteration\": np.array([\"BoxcountRatio\",\"spacialLacunarity\"]) }\n",
    "    for i in range(len(threads)):\n",
    "        BoxCountR_SpacialLac_map = np.array(threads[i].join())\n",
    "        BoxCountR_SpacialLac_map_Dict[i]= BoxCountR_SpacialLac_map\n",
    "        if verbosity == True :\n",
    "            #print(BoxCountR_SpacialLac_map)\n",
    "            print(BoxCountR_SpacialLac_map.shape)\n",
    "            print(type(BoxCountR_SpacialLac_map))\n",
    "            print(\"Thread \",i,\" JOINED\")\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(round(end - start,3),\"seconds for spacial boxcounting with \",i+1, \"iterations/scalings\")\n",
    "    \n",
    "    if verbosity:\n",
    "        input(\"Press any key to continue with next file. \\n Attention: verbosity adds much size to the output of jupyter notebook. If the file > 120'ish MB, jupyter notebook crashes. So use just for debugging for beware. \")\n",
    "    \n",
    "    return BoxCountR_SpacialLac_map_Dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 Validation of performance - visualizing and saving processed images with spacial boxcounting\n",
    "\n",
    "\n",
    "By iterating over a picture containing folder and measuring the time difference of the multi threaded boxcounting function, the standard python compiler can be compared to the numba-jit compiler in terms of computational efficiency. \n",
    "\n",
    "If the variable verbosity is set to true, additional information and the generated arrays are displayed, but can eventually buffer overflow the output of the jupyter notebook file, resulting in a unaccessible file.\n",
    "The following function computes the first 100 pictures specified by a foldername, tracks the time for executing the multithreaded boxcounting and displays corresponding outputs to visualize the spacial boxcounting.\n",
    "If the folder name \"MISC\" is chosen, the images from the chosen folder is processed and by user input can be specified, if the calculated arrays are to be saved in the folder generated images like shown in figure 8.\n",
    "\n",
    "![BoxcountingURL](https://raw.githubusercontent.com/ollimacp/spacial-boxcounting-cpu-gpu/main/0Data/generated_imgs/17_3_900x.png)\n",
    "Figure 8: Example generated image with the boxcounting ratios (BCR) and lacunaritys (LAC) to their boxsize (2,4,8,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to execute spacial boxcounting, track executed time and maybe display/save pictures? \n",
      " y/n n\n"
     ]
    }
   ],
   "source": [
    "verbosity = False\n",
    "\n",
    "foldername = \"Images\" # The foldername  where the machine learning dataset is based on\n",
    "#foldername = \"MISC\"   # for saving special fotos iterate over MISC\n",
    "whereTObreakIteration = 100 #abort after 100 pictures for time testing\n",
    "\n",
    " \n",
    "\n",
    "def Show_Pictures(foldername):\n",
    "    savepicture = None\n",
    "    display_images = input(\"(Y/n) Do you want to display the processed images? Attention: Output gets big quickly and can resolve in a soft brick of the jupyter notebook, so beware\")\n",
    "\n",
    "    from os import listdir\n",
    "    DataFolder = FileParentPath + \"/0Data/\"+ foldername + \"/\"\n",
    "    filelist = [f for f in listdir(DataFolder)]\n",
    "    print(\"The specified folder for display pictures and fractal derivatives: \",DataFolder)\n",
    "    totaltime = 0.0\n",
    "    counter = 0\n",
    "    for index, filename in enumerate(filelist):\n",
    "        counter +=1\n",
    "        print(\"Picture\",index+1,\"of\",whereTObreakIteration)\n",
    "        if counter == whereTObreakIteration +1:\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        try:   \n",
    "            filepath = DataFolder+ filename \n",
    "            print(filename)\n",
    "            image = Image.open(filepath) #Load Image with Pillow\n",
    "            \n",
    "            #Cause rgb has 3 channels, the channels are flattend to 1 channel by concatenating the channels side by side\n",
    "            ChannleDimension = len(str(image.mode)) # grey -> 1 chan , rgb 3 channle\n",
    "            \n",
    "            if verbosity == True:\n",
    "                # summarize some details about the image\n",
    "                print(image.format,image.size)\n",
    "                print(image.mode)\n",
    "                # show the image\n",
    "                #image.show()\n",
    "                print(\"Incoming image has\",ChannleDimension, \"channels\")\n",
    "\n",
    "            #init possible channels\n",
    "            C1, C2, C3, C4, C5, C6 = None, None, None, None, None, None \n",
    "            channellist = [C1,C2,C3,C4,C5,C6]\n",
    "            #Cropped channellist to actual used channels\n",
    "            croppedChannelList = channellist[0:ChannleDimension-1]\n",
    "            #slit channels to variables C1...C6\n",
    "            croppedChannelList = image.split()        \n",
    "            #Stacking channels from left to right\n",
    "            initEntry = None\n",
    "            stackedchannels = np.array(initEntry)\n",
    "            for index, channel in enumerate(croppedChannelList):\n",
    "                PicNumpy = np.array(channel)\n",
    "                if verbosity == True:\n",
    "                    channel.show()  \n",
    "                    print(channel)\n",
    "                    print(PicNumpy)\n",
    "                    print(PicNumpy.shape)\n",
    "\n",
    "                if index == 0:\n",
    "                    stackedchannels = PicNumpy\n",
    "                else:\n",
    "                    stackedchannels = np.concatenate((stackedchannels,PicNumpy),axis=1)\n",
    "\n",
    "            if verbosity == True:\n",
    "                print(stackedchannels)\n",
    "                print(stackedchannels.shape)\n",
    "                \n",
    "            npOutputFile = stackedchannels  #is the preprocessed picture as grayscale and flattened channels\n",
    "\n",
    "\n",
    "            \n",
    "            # MULTITHREAD BOXCOUNT Execution-------------------------------------\n",
    "\n",
    "            start = time.time()   #start time here for just to compare boxcount performance, everything before is preprocessing \n",
    "                                  # and gpu-version also has preprocessing steps\n",
    "            BoxCountR_SpacialLac_map_Dict = MultithreadBoxcount(npOutputFile)\n",
    "        \n",
    "            end = time.time()\n",
    "            \n",
    "            timethisround = end-start\n",
    "            totaltime += timethisround\n",
    "\n",
    "            BCRmap2 , Lakmap2 = BoxCountR_SpacialLac_map_Dict[0]\n",
    "            BCRmap4 , Lakmap4 = BoxCountR_SpacialLac_map_Dict[1]\n",
    "            BCRmap8, Lakmap8 = BoxCountR_SpacialLac_map_Dict[2]\n",
    "            BCRmap16 , Lakmap16 = BoxCountR_SpacialLac_map_Dict[3]\n",
    "\n",
    "            if display_images == \"\" or display_images == \"y\":\n",
    "\n",
    "                showNPArrayAsImage(npOutputFile, \"Original Picture\", \"gray\")\n",
    "\n",
    "                #source:[18] https://stackoverflow.com/questions/22053274/grid-of-images-in-matplotlib-with-no-padding\n",
    "\n",
    "                max_cols = 2\n",
    "                fig, axes = plt.subplots(nrows=4, ncols=max_cols, figsize=(10,16))\n",
    "                lablelist = [BCRmap2, Lakmap2,BCRmap4 , Lakmap4,BCRmap8, Lakmap8,  BCRmap16 , Lakmap16 ]\n",
    "\n",
    "                titlelist = [\"BCR2\", \"LAC2\", \"BCR4\", \"LAC4\", \"BCR8\", \"LAC8\",\"BCR16\", \"LAC16\"]  #, \"NN BCR2\", \"NN LAC2\",   ]\n",
    "                for idx, image in enumerate(lablelist):\n",
    "                    row = idx // max_cols\n",
    "                    col = idx % max_cols\n",
    "                    #axes[row, col].axis(\"off\")\n",
    "                    axes[row,col].imshow(image, cmap=\"gray\", aspect=\"auto\")\n",
    "                    axes[row, col].set_title(titlelist[idx])\n",
    "                    # label x-axis and y-axis \n",
    "                    #axes[row, col].set_ylabel(ylabellist[idx]) \n",
    "                    #axes[row, col].set_xlabel(ylabellist[idx]) \n",
    "\n",
    "                plt.subplots_adjust(wspace=.1, hspace=.2)\n",
    "            \n",
    "            if foldername == \"MISC\":\n",
    "                if savepicture == None:\n",
    "                    savepicture = input(\"do you want to save pictures in the folder MISC into generated images? \\n (Y/y) or not (n) or NEVER for just diplay output (N)\")\n",
    "\n",
    "                if savepicture == None or savepicture == \"y\" or savepicture == \"Y\" or savepicture == \"\":\n",
    "                    saveplace = FileParentPath + \"/0Data/generated_imgs/\"+filename[:-3] +\"png\"\n",
    "                    print(\"saveplace is\", saveplace)\n",
    "                    plt.savefig(saveplace , bbox_inches='tight')\n",
    "                    continue\n",
    "\n",
    "                elif savepicture == \"N\":\n",
    "                    pass\n",
    "\n",
    "                else:\n",
    "                    savepicture = None\n",
    "                    pass\n",
    "\n",
    "\n",
    "            plt.show()\n",
    "                            \n",
    "            '''\n",
    "            #Different kind of displaying images\n",
    "\n",
    "            showNPArrayAsImage(BCRmap2, \"BCRmap2\", \"gray\")\n",
    "            showNPArrayAsImage(Lakmap2, \"Lakmap2\", \"gray\")\n",
    "\n",
    "            showNPArrayAsImage(BCRmap4, \"BCRmap4\", \"gray\")\n",
    "            showNPArrayAsImage(Lakmap4, \"Lakmap4\", \"gray\")\n",
    "\n",
    "            showNPAr21rayAsImage(BCRmap8, \"BCRmap8\", \"gray\")\n",
    "            showNPArrayAsImage(Lakmap8, \"Lakmap8\", \"gray\")\n",
    "\n",
    "            showNPArrayAsImage(BCRmap16, \"BCRmap16\", \"gray\")\n",
    "            showNPArrayAsImage(Lakmap16, \"Lakmap16\", \"gray\")\n",
    "            input()\n",
    "            '''\n",
    "            \n",
    "        except :\n",
    "            PrintException()\n",
    "            print(\"Exception hit while showing pictures, assume abort, so break loop and continue with the script\")\n",
    "            input()\n",
    "            break    \n",
    "    \n",
    "    #CALC time metrics to compare with gpu-Version\n",
    "    mean_timePERbatch = totaltime / float(whereTObreakIteration)\n",
    "    MegapixelPERsecond =  round( (1.0 * float(npOutputFile.shape[0]) * float(npOutputFile.shape[1])) /(mean_timePERbatch* 1000000 ) ,2)\n",
    "    #print(\"compiler\", compiler)\n",
    "    print(\"CPU python code\",\" with\", mean_timePERbatch, \" seconds/Picture with a pixelthroughput of\",MegapixelPERsecond )\n",
    "    \n",
    "youwanttoshow = input(\"Do you want to execute spacial boxcounting, track executed time and maybe display/save pictures? \\n y/n\")\n",
    "\n",
    "if youwanttoshow == \"y\":\n",
    "    Show_Pictures(foldername)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Utilizing the capabilities of spacial Boxcounting by\n",
    "\n",
    "The boxcount ratio is an indicator for spacial complexity like the fractal dimension, or hausdorff dimension and it can be calculated with boxcounts ranging over many scales. The more boxes out of all possible boxes are counted,  the more the boxcount ratio approaches one. Arrays with similar structures have  similar boxsize-scaled boxcount distributions, if the dimensions of the arrays remain constant.  \n",
    "The lacunarity is an indicator for spacial heterogeneity on a specific scaling which is defined by the boxsize. The spacial heterogeneity can become useful for edgedetection on a specific scale, or dimensionallity reduction.\n",
    "\n",
    "The two following tasks are just examples for using the boxcounting algorithm.\n",
    "\n",
    "### 3.4.1 Similarity search\n",
    "\n",
    "Comparing the boxcounts and lacunaritys of chosen boxsizes over many files can enable a controllable similarity search. \n",
    "The variable similarity equals the sum of the mean of all boxcount ratios for each boxsize and its diffrence to other files. The more the similarity is approaching zero, the more similar the chosen picture should be. \n",
    "To be accurate the spacial dimensions of pictures or arrays have to be equal in x,y and the maximum intrinsic value, when the lacunarity is used.\n",
    "If just the boxcount ratio is used, also pictures/arrays of different sizes can be compared, because every boxcount is normalized against the maximum number of possible boxes for each boxsize respectively.\n",
    "\n",
    "The similar picture search function is executed by using the folder name of the search space and the path to the picture, it should be compared to. The corresponding pictures are characterized with the spacial boxcounting and saved in a dictionary. Thereafter the similarity is calculated and sorted to display the first 50 images that are the most similar to the picture to be searched for. Since the default search picture is also in the folder of the search space, the second picture should be the same as the first one.\n",
    "\n",
    "\n",
    "### 3.4.2  Edge detection with controllable edge width \n",
    "\n",
    "Edges often come with contrast, which results in an increased standard deviation in the value distribution of the input array cropped by the boxboundries.\n",
    "\n",
    "These mathematical properties of the lacunarity and the spacial boxcounting derives a scaled down version of the pictures, which highlights regions of spacial complexity and heterogeneity. \n",
    "The lacunarity could be utilized in an edge detection algorithm highlighting all edges at a chosen scale, aka boxsize.\n",
    "\n",
    "The example edge detection function is executed with an input picture to characterize it with the spacial boxcounting at all specified boxsizes. The results are displayed and the user can specify the scaling to choose the boxsize to get the desired output. Choosing a boxsize of 2 results in a second long task revealing fine edges in the picture. Increasing the boxsize will downscale the picture, which results in revealing coarser edges found within the picture and with much faster processing time in the millisecond range.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to search for similar pictures in a dataset? \n",
      " y/n y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.352 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "7.35248875617981 seconds for fractal characterization of the picture to be seached for.\n",
      "10_1_1800x.bmp\n",
      "2.154 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "10_1_3700x.bmp\n",
      "1.981 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "10_1_900x.bmp\n",
      "2.187 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "10_2_1800x.bmp\n",
      "2.216 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "10_2_3700x.bmp\n",
      "2.146 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "10_2_900x.bmp\n",
      "2.387 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "10_3_1800x.bmp\n",
      "2.086 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "10_3_3700x.bmp\n",
      "1.959 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "10_3_900x.bmp\n",
      "2.017 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "10_4_1800x.bmp\n",
      "2.353 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "10_4_3700x.bmp\n",
      "2.439 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "10_4_900x.bmp\n",
      "2.196 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "11_1_1800x.bmp\n",
      "2.105 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "11_1_3700x.bmp\n",
      "2.217 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "11_1_900x.bmp\n",
      "2.108 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "11_2_1800x.bmp\n",
      "2.185 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "11_2_3700x.bmp\n",
      "1.979 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "11_2_900x.bmp\n",
      "2.206 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "11_3_1800x.bmp\n",
      "2.207 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "11_3_3700x.bmp\n",
      "2.346 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "11_3_900x.bmp\n",
      "2.393 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "11_4_1800x.bmp\n",
      "3.25 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "11_4_3700x.bmp\n",
      "2.366 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "11_4_900x.bmp\n",
      "3.273 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "12.1_1800x.bmp\n",
      "2.569 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "12.3_1800x.bmp\n",
      "2.533 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "12.4+7.3_1800x.bmp\n",
      "2.976 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "12.4_1800x.bmp\n",
      "2.818 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "12_1_1800x.bmp\n",
      "2.316 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "12_1_3700x.bmp\n",
      "4.173 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "12_1_900x.bmp\n",
      "3.116 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "12_3_1800x.bmp\n",
      "2.062 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "12_3_3700x.bmp\n",
      "2.604 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "12_3_900x.bmp\n",
      "3.04 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "12_4_1800x.bmp\n",
      "3.099 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "12_4_3700x.bmp\n",
      "3.441 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "12_4_900x.bmp\n",
      "1.934 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "13.2_1800x.bmp\n",
      "3.015 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "13.4_1800x.bmp\n",
      "2.284 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "13_1_1800x.bmp\n",
      "3.089 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "13_1_3700x.bmp\n",
      "2.429 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "13_1_900x.bmp\n",
      "2.56 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "13_2_1800x.bmp\n",
      "3.325 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "13_2_3700x.bmp\n",
      "3.308 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "13_2_900x.bmp\n",
      "3.507 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "13_3_1800x.bmp\n",
      "2.379 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "13_3_3700x.bmp\n",
      "2.856 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "13_3_900x.bmp\n",
      "2.844 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "13_4_1800x.bmp\n",
      "2.105 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "13_4_3700x.bmp\n",
      "3.043 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "13_4_900x.bmp\n",
      "3.153 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "14.4_1800x.bmp\n",
      "3.253 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "14_1_1800x.bmp\n",
      "3.369 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "14_1_3700x.bmp\n",
      "4.113 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "14_1_900x.bmp\n",
      "2.701 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "14_2_1800x.bmp\n",
      "2.539 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "14_2_3700x.bmp\n",
      "2.413 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "14_2_900x.bmp\n",
      "4.733 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "14_3_1800x.bmp\n",
      "3.235 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "14_3_3700x.bmp\n",
      "2.245 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "14_3_900x.bmp\n",
      "2.272 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "14_4_1800x.bmp\n",
      "2.17 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "14_4_3700x.bmp\n",
      "3.103 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "14_4_900x.bmp\n",
      "2.388 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "15_1_1800x.bmp\n",
      "2.275 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "15_1_3700x.bmp\n",
      "3.207 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "15_1_900x.bmp\n",
      "2.429 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "15_2_1800x.bmp\n",
      "3.356 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "15_2_3700x.bmp\n",
      "3.238 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "15_2_900x.bmp\n",
      "4.097 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "15_3_1800x.bmp\n",
      "3.228 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "15_3_3700x.bmp\n",
      "4.029 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "15_3_900x.bmp\n",
      "2.324 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "15_4_1800x.bmp\n",
      "2.049 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "15_4_3700x.bmp\n",
      "2.928 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "15_4_900x.bmp\n",
      "2.283 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "16_1_1800x.bmp\n",
      "2.089 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "16_1_3700x.bmp\n",
      "2.969 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "16_1_900x.bmp\n",
      "3.095 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "16_2_1800x.bmp\n",
      "3.083 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "16_2_3700x.bmp\n",
      "2.858 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "16_2_900x.bmp\n",
      "2.233 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "16_3_1800x.bmp\n",
      "2.701 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "16_3_3700x.bmp\n",
      "3.004 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "16_3_900x.bmp\n",
      "2.122 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "16_4_1800x.bmp\n",
      "2.391 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "16_4_3700x.bmp\n",
      "2.189 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "16_4_900x.bmp\n",
      "3.034 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "17.1_1800x.bmp\n",
      "2.065 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "17_1_1800x.bmp\n",
      "2.95 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "17_1_3700x.bmp\n",
      "2.023 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "17_1_900x.bmp\n",
      "2.922 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "17_3_1800x.bmp\n",
      "3.015 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "17_3_3700x.bmp\n",
      "2.904 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "17_3_900x.bmp\n",
      "2.03 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "17_3_Rand.bmp\n",
      "2.819 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "17_4_1800x.bmp\n",
      "2.929 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "17_4_3700x.bmp\n",
      "1.986 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "17_4_900x.bmp\n",
      "3.081 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "18.3+7.3_1800x.bmp\n",
      "2.029 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "18.3_1800x.bmp\n",
      "2.974 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "18_1_1800x.bmp\n",
      "3.108 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "18_1_3700x.bmp\n",
      "3.324 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "18_1_900x.bmp\n",
      "2.298 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "18_2_1800x.bmp\n",
      "2.106 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "18_2_3700x.bmp\n",
      "2.139 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "18_2_900x.bmp\n",
      "3.228 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "18_3_1800x.bmp\n",
      "2.224 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "18_3_3700x.bmp\n",
      "2.271 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "18_3_900x.bmp\n",
      "3.349 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "18_4_1800x.bmp\n",
      "3.269 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "18_4_3700x.bmp\n",
      "2.034 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "18_4_900x.bmp\n",
      "3.17 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "19.1_1800x.bmp\n",
      "2.27 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "19_1_1800x.bmp\n",
      "3.697 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "19_1_3700x.bmp\n",
      "2.613 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "19_1_900x.bmp\n",
      "2.408 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "19_3_1800x.bmp\n",
      "2.138 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "19_3_3700x.bmp\n",
      "3.047 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "19_3_900x.bmp\n",
      "3.051 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "19_3_Rand.bmp\n",
      "2.183 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "19_4_1800x.bmp\n",
      "3.01 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "19_4_3700x.bmp\n",
      "2.278 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "19_4_900x.bmp\n",
      "2.216 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "19_4_Rand.bmp\n",
      "2.454 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "1_1_1800x.bmp\n",
      "3.259 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "1_1_3700x.bmp\n",
      "3.167 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "1_1_900x.bmp\n",
      "3.128 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "1_1_x100.bmp\n",
      "2.414 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "1_1_x200.bmp\n",
      "2.176 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "1_1_x30.bmp\n",
      "2.955 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "1_1_x400.bmp\n",
      "3.01 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "1_1_x50.bmp\n",
      "2.049 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "1_1_x800.bmp\n",
      "2.597 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "1_1_x800_2.bmp\n",
      "3.189 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "1_2_x1800.bmp\n",
      "2.237 seconds for spacial boxcounting with  4 iterations/scalings\n",
      "1_2_x7500.bmp\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    254\u001b[0m youwanttosearch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDo you want to search for similar pictures in a dataset? \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m y/n\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m youwanttosearch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 257\u001b[0m     \u001b[43msearch_similar_picture_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfoldername\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpictureINquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m#EDGEDETECTION--------------------------------\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m#pictureINquestion = FileParentPath +\"/0Data/Images/\"\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m#pictureINquestion += \"7_4_1800x.bmp\"\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m#pictureINquestion += \"10_1_900x.bmp\"\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m#pictureINquestion += \"12_4_900x.bmp\"\u001b[39;00m\n\u001b[0;32m    268\u001b[0m pictureINquestion \u001b[38;5;241m=\u001b[39m  FileParentPath \u001b[38;5;241m+\u001b[39m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/0Data/spacial_search_examples/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36msearch_similar_picture_with\u001b[1;34m(foldername, pictureINquestion)\u001b[0m\n\u001b[0;32m    162\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()   \u001b[38;5;66;03m#start time here for just to compare boxcount performance, everything before is preprocessing \u001b[39;00m\n\u001b[0;32m    163\u001b[0m                       \u001b[38;5;66;03m# and gpu-version also has preprocessing steps\u001b[39;00m\n\u001b[1;32m--> 164\u001b[0m BoxCountR_SpacialLac_map_Dict \u001b[38;5;241m=\u001b[39m \u001b[43mMultithreadBoxcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnpOutputFile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    167\u001b[0m timethisround \u001b[38;5;241m=\u001b[39m end\u001b[38;5;241m-\u001b[39mstart\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mMultithreadBoxcount\u001b[1;34m(npOutputFile)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(threads)):\n\u001b[0;32m    212\u001b[0m     threads[i] \u001b[38;5;241m=\u001b[39m ThreadWithReturnValue(target\u001b[38;5;241m=\u001b[39mBoxcountBoxsizeWorker, args\u001b[38;5;241m=\u001b[39m(npOutputFile, i))\n\u001b[1;32m--> 213\u001b[0m     \u001b[43mthreads\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbosity \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread \u001b[39m\u001b[38;5;124m\"\u001b[39m,i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m has started\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:897\u001b[0m, in \u001b[0;36mThread.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    895\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m _limbo[\u001b[38;5;28mself\u001b[39m]\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m--> 897\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_started\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:574\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    572\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 574\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Attention: Picture has to be same size/volume, when lacunarity is taken into account\n",
    "#           when just using boxcounting ratio, pics can be different\n",
    "\n",
    "#loaded picture to search for\n",
    "pictureINquestion = FileParentPath +\"/0Data/spacial_search_examples/\"\n",
    "#pictureINquestion += \"hydrophobic_leaf_x1800.bmp\"\n",
    "#pictureINquestion += \"7_3_1800x.bmp\"\n",
    "pictureINquestion += \"Ripple_RM4_x1800.bmp\"\n",
    "#path to directory of search space\n",
    "foldername = FileParentPath + \"/0Data/Images/\"\n",
    "\n",
    "fractal_parameter_dict = {}    # dict with picturename and all scores for bcr/lak over boxsizes 2,4 8, 16\n",
    "\n",
    "#simple example of search for similar pictures\n",
    "def search_similar_picture_with(foldername, pictureINquestion):\n",
    "    \n",
    "    imageToSeachFor = Image.open(pictureINquestion)  # load picture in question\n",
    "\n",
    "    #Cause rgb has 3 channels, the channels are flattend to 1 channel by concatenating the channels side by side\n",
    "    ChannleDimension = len(str(imageToSeachFor.mode)) # grey -> 1 chan , rgb 3 channle\n",
    "\n",
    "    if verbosity == True:\n",
    "        # summarize some details about the image\n",
    "        print(imageToSeachFor.format,imageToSeachFor.size)\n",
    "        print(imageToSeachFor.mode)\n",
    "        print(\"Incoming image has\",ChannleDimension, \"channels\")\n",
    "\n",
    "    #init possible channels\n",
    "    C1, C2, C3, C4, C5, C6 = None, None, None, None, None, None \n",
    "    channellist = [C1,C2,C3,C4,C5,C6]\n",
    "    #Cropp channellist to actual used channels\n",
    "    croppedChannelList = channellist[0:ChannleDimension-1]\n",
    "\n",
    "    croppedChannelList = imageToSeachFor.split()        \n",
    "    #Stacking channels from left to right\n",
    "    initEntry = None\n",
    "    stackedchannels = np.array(initEntry)\n",
    "    for index, channel in enumerate(croppedChannelList):\n",
    "        PicNumpy = np.array(channel)\n",
    "        if verbosity == True:\n",
    "            channel.show()  \n",
    "            print(channel)\n",
    "            print(PicNumpy)\n",
    "            print(PicNumpy.shape)\n",
    "\n",
    "        if index == 0:\n",
    "            stackedchannels = PicNumpy\n",
    "        else:\n",
    "            stackedchannels = np.concatenate((stackedchannels,PicNumpy),axis=1)\n",
    "\n",
    "    if verbosity == True:\n",
    "        print(stackedchannels)\n",
    "        print(stackedchannels.shape)\n",
    "\n",
    "    npOutputFileToSearchFor = stackedchannels\n",
    "\n",
    "    \n",
    "    # MULTITHREAD BOXCOUNT Execution----------------------\n",
    "    # calc boxcountratio and lacunarity to characterize the picture\n",
    "    start = time.time()   #start time here for just to compare boxcount performance, everything before is preprocessing \n",
    "    # and gpu-version also has preprocessing steps\n",
    "    BoxCountR_SpacialLac_map_Dict = MultithreadBoxcount(npOutputFileToSearchFor)\n",
    "    end = time.time()\n",
    "\n",
    "    timethisround = end-start\n",
    "\n",
    "    print(timethisround, \"seconds for fractal characterization of the picture to be seached for.\")\n",
    "    \n",
    "    BCRmap2 , Lakmap2 = BoxCountR_SpacialLac_map_Dict[0]\n",
    "    BCRmap4 , Lakmap4 = BoxCountR_SpacialLac_map_Dict[1]\n",
    "    BCRmap8, Lakmap8 = BoxCountR_SpacialLac_map_Dict[2]\n",
    "    BCRmap16 , Lakmap16 = BoxCountR_SpacialLac_map_Dict[3]\n",
    "\n",
    "\n",
    "    #take just the mean of the bcr ratios, since ratio is normalized against all possible boxes at each scaling\n",
    "    # which lac is not and soforth maybe arrays of different sizes can be compared against\n",
    "    meanBCR2 = np.mean(BCRmap2)\n",
    "    meanBCR4 = np.mean(BCRmap4)\n",
    "    meanBCR8 = np.mean(BCRmap8)\n",
    "    meanBCR16 = np.mean(BCRmap16)\n",
    "\n",
    "    \n",
    "    # store bcr and lac for each scale in a dict with the key of the filname\n",
    "    #fractal_parameter_dict[pictureINquestion] = np.array([meanBCR2,meanBCR4, meanBCR8, meanBCR16])\n",
    "\n",
    "    SumLAC2 = np.mean(Lakmap2)\n",
    "    SumLAC4 = np.mean(Lakmap4)\n",
    "    SumLAC8 = np.mean(Lakmap8)\n",
    "    SumLAC16 = np.mean(Lakmap16)\n",
    "        \n",
    "        # store bcr and lac for each scale in a dict with the key of the filname\n",
    "    fractal_parameter_dict[pictureINquestion] = np.array([meanBCR2,meanBCR4, meanBCR8, meanBCR16, SumLAC2, SumLAC4, SumLAC8, SumLAC16])\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    #CHARACTERIZING PICTURE TO BE SEARCHED FOR DONE,...\n",
    "    #now iterate over the chosen folder and characterize as well\n",
    "\n",
    "    #DataFolder = FileParentPath + \"/0Data\"+ foldername\n",
    "    filelist = [f for f in listdir(foldername)]\n",
    "\n",
    "    totaltime = 0.0\n",
    "    counter = 0\n",
    "    #iterate over all pictures and\n",
    "    for index, filename in enumerate(filelist):\n",
    "        counter +=1\n",
    "        filepath = foldername+ filename \n",
    "        print(filename)\n",
    "        #Load Image with Pillow\n",
    "        image = Image.open(filepath)\n",
    "\n",
    "        #Cause rgb has 3 channels, the channels are flattend to 1 channel by concatenating the channels side by side\n",
    "        ChannleDimension = len(str(image.mode)) # grey -> 1 chan , rgb 3 channle\n",
    "\n",
    "        if verbosity == True:\n",
    "            # summarize some details about the image\n",
    "            print(image.format,image.size)\n",
    "            print(image.mode)\n",
    "            # show the image\n",
    "            #image.show()\n",
    "            print(\"Incoming image has\",ChannleDimension, \"channels\")\n",
    "\n",
    "        #init possible channels\n",
    "        C1, C2, C3, C4, C5, C6 = None, None, None, None, None, None \n",
    "        channellist = [C1,C2,C3,C4,C5,C6]\n",
    "        #Cropp channellist to actual used channels\n",
    "        croppedChannelList = channellist[0:ChannleDimension-1]\n",
    "        #slit channels to variables C1...C6\n",
    "\n",
    "\n",
    "        croppedChannelList = image.split()        \n",
    "        #Stacking channels from left to right\n",
    "        initEntry = None\n",
    "        stackedchannels = np.array(initEntry)\n",
    "        #stackedchannels = None\n",
    "        for index, channel in enumerate(croppedChannelList):\n",
    "            PicNumpy = np.array(channel)\n",
    "            if verbosity == True:\n",
    "                channel.show()  \n",
    "                print(channel)\n",
    "                print(PicNumpy)\n",
    "                print(PicNumpy.shape)\n",
    "\n",
    "            if index == 0:\n",
    "                stackedchannels = PicNumpy\n",
    "            else:\n",
    "                stackedchannels = np.concatenate((stackedchannels,PicNumpy),axis=1)\n",
    "\n",
    "        if verbosity == True:\n",
    "            print(stackedchannels)\n",
    "            print(stackedchannels.shape)\n",
    "\n",
    "        npOutputFile = stackedchannels\n",
    "\n",
    "\n",
    "        #calc bcr and lac\n",
    "\n",
    "        # MULTITHREAD BOXCOUNT Execution\n",
    "\n",
    "        start = time.time()   #start time here for just to compare boxcount performance, everything before is preprocessing \n",
    "                              # and gpu-version also has preprocessing steps\n",
    "        BoxCountR_SpacialLac_map_Dict = MultithreadBoxcount(npOutputFile)\n",
    "        end = time.time()\n",
    "\n",
    "        timethisround = end-start\n",
    "\n",
    "\n",
    "        BCRmap2 , Lakmap2 = BoxCountR_SpacialLac_map_Dict[0]\n",
    "        BCRmap4 , Lakmap4 = BoxCountR_SpacialLac_map_Dict[1]\n",
    "        BCRmap8, Lakmap8 = BoxCountR_SpacialLac_map_Dict[2]\n",
    "        BCRmap16 , Lakmap16 = BoxCountR_SpacialLac_map_Dict[3]\n",
    "\n",
    "        #TEST: take just the mean of the bcr ratios, since ratio is normalized against all possible boxes at each scaling\n",
    "        # which lac is not and soforth maybe arrays of different sizes can be compared against\n",
    "        meanBCR2 = np.mean(BCRmap2)\n",
    "        meanBCR4 = np.mean(BCRmap4)\n",
    "        meanBCR8 = np.mean(BCRmap8)\n",
    "        meanBCR16 = np.mean(BCRmap16)\n",
    "\n",
    "\n",
    "\n",
    "        SumLAC2 = np.mean(Lakmap2)\n",
    "        SumLAC4 = np.mean(Lakmap4)\n",
    "        SumLAC8 = np.mean(Lakmap8)\n",
    "        SumLAC16 = np.mean(Lakmap16)\n",
    "        \n",
    "        # store bcr and lac for each scale in a dict with the key of the filname\n",
    "        fractal_parameter_dict[filepath] = np.array([meanBCR2,meanBCR4, meanBCR8, meanBCR16, SumLAC2, SumLAC4, SumLAC8, SumLAC16])\n",
    "\n",
    "\n",
    "    #sort the pictures with minimizing values scaled by scaledependent scaling factor\n",
    "\n",
    "    #If you value coarse topograpfic features, just increase scalingfactor for the latter values\n",
    "    #scalef. for Boxs.2, 4,    8,   16 \n",
    "    #scaling for Lacunarity lower, cause bcr 0..1 and lac 0....xxxxxxx \n",
    "    scalinglist = np.array([0.25,0.25,0.25,0.25,0.05,0.05,0.05,0.05 ])  #scaling value for each boxsize aka scalingfactor\n",
    "\n",
    "    similarity_dict = {}\n",
    "\n",
    "    #tocompareagainst = np.array()\n",
    "    tocompareagainst = fractal_parameter_dict[pictureINquestion]\n",
    "\n",
    "    similarity_dict[pictureINquestion] = np.sum([0.0])\n",
    "\n",
    "    for filepath, BCRlist in fractal_parameter_dict.items():\n",
    "        if filepath == pictureINquestion:\n",
    "            #if the searched for picture is current one, just continue to next element,\n",
    "            # cause similarity is 0\n",
    "            continue\n",
    "        \n",
    "        similarity = BCRlist - tocompareagainst   #Difference of current ratios against the values for the picture in question.\n",
    "        similarity = np.absolute(similarity)  # we just care about tha absolut diffrence to the target\n",
    "        similarity = np.multiply(similarity, scalinglist) #elementwise multiplication for scaling\n",
    "        similarity = np.sum(similarity)   # to get to one value just take the sum of all elements\n",
    "        \n",
    "        similarity_dict[filepath] = similarity\n",
    "    \n",
    "    \n",
    "    #source [19] https://stackabuse.com/how-to-sort-dictionary-by-value-in-python/\n",
    "    fig=plt.figure()\n",
    "\n",
    "    sorted_values = sorted(similarity_dict.values()) # Sort the values\n",
    "    sorted_dict = {}\n",
    "\n",
    "    for index, current_similarity in enumerate(sorted_values):\n",
    "        if index == 0:\n",
    "            print(\"Picture to search for\")\n",
    "        if index == 10:\n",
    "            #just showing the first 50 pictures for conveniance\n",
    "            break\n",
    "            \n",
    "        #loop for sorted values begin from 0 and ascending \n",
    "        for filepath in similarity_dict.keys():\n",
    "            if similarity_dict[filepath] == current_similarity:\n",
    "                #found entry\n",
    "                # reading the image \n",
    "                foundImage = img.imread(filepath) \n",
    "                #img = PIL.Image.open(x)\n",
    "                plt.subplot(4,4,index+1)\n",
    "                chosentitle= \"Similarity = \",str(current_similarity)\n",
    "                plt.title(chosentitle)\n",
    "                plt.axis('off')\n",
    "                plt.imshow(foundImage, cmap='gray')\n",
    "\n",
    "                #sorted_dict[key] = similarity_dict[key]\n",
    "                break\n",
    "\n",
    "        #print(sorted_dict)    \n",
    "        plt.show(block=False)\n",
    "\n",
    "\n",
    "youwanttosearch = input(\"Do you want to search for similar pictures in a dataset? \\n y/n\")\n",
    "\n",
    "if youwanttosearch == \"y\":\n",
    "    search_similar_picture_with(foldername, pictureINquestion)\n",
    "\n",
    "    \n",
    "    \n",
    "#EDGEDETECTION--------------------------------\n",
    "    \n",
    "#pictureINquestion = FileParentPath +\"/0Data/Images/\"\n",
    "#pictureINquestion += \"7_4_1800x.bmp\"\n",
    "#pictureINquestion += \"10_1_900x.bmp\"\n",
    "#pictureINquestion += \"12_4_900x.bmp\"\n",
    "\n",
    "pictureINquestion =  FileParentPath +  \"/0Data/spacial_search_examples/\"\n",
    "pictureINquestion += \"edgedetect.bmp\"\n",
    "\n",
    "\n",
    "    \n",
    "def edgedectecion_with(pictureINquestion):\n",
    "    #load image\n",
    "    ChosenImage = img.imread(pictureINquestion) \n",
    "    # full boxcounting on picture in question and view as a grid\n",
    "\n",
    "    # MULTITHREAD BOXCOUNT Execution\n",
    "\n",
    "    start = time.time()   #start time here for just to compare boxcount performance, everything before is preprocessing \n",
    "                          # and gpu-version also has preprocessing steps\n",
    "    BoxCountR_SpacialLac_map_Dict = MultithreadBoxcount(ChosenImage)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    timethisround = end-start\n",
    "\n",
    "    BCRmap2 , Lakmap2 = BoxCountR_SpacialLac_map_Dict[0]\n",
    "    BCRmap4 , Lakmap4 = BoxCountR_SpacialLac_map_Dict[1]\n",
    "    BCRmap8, Lakmap8 = BoxCountR_SpacialLac_map_Dict[2]\n",
    "    BCRmap16 , Lakmap16 = BoxCountR_SpacialLac_map_Dict[3]\n",
    "    \n",
    "    showNPArrayAsImage(ChosenImage, \"Original Picture\", \"gray\")\n",
    "\n",
    "    #source: [17] https://stackoverflow.com/questions/22053274/grid-of-images-in-matplotlib-with-no-padding\n",
    "\n",
    "    max_cols = 2\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=max_cols, figsize=(14,10))\n",
    "    lablelist = [ Lakmap2, Lakmap4, Lakmap8, Lakmap16 ]\n",
    "\n",
    "    titlelist = [\"LAC2\", \"LAC4\", \"LAC8\",\"LAC16\"]  \n",
    "    for idx, image in enumerate(lablelist):\n",
    "        row = idx // max_cols\n",
    "        col = idx % max_cols\n",
    "        #axes[row, col].axis(\"off\")\n",
    "        axes[row,col].imshow(image, cmap=\"gray\", aspect=\"auto\")\n",
    "        axes[row, col].set_title(titlelist[idx])\n",
    "        # label x-axis and y-axis \n",
    "        #axes[row, col].set_ylabel(ylabellist[idx]) \n",
    "        #axes[row, col].set_xlabel(ylabellist[idx]) \n",
    "\n",
    "    plt.subplots_adjust(wspace=.1, hspace=.2)\n",
    "    plt.show()\n",
    "    \n",
    "    # evaluate the picture and what scaling and so forth boxsize for the edgedetection has to be choosed\n",
    "    #choose boxsize\n",
    "    print(\"0 detect fine grid(slow)... 3 detect with coarse grid (fast)\")\n",
    "    chosenscaling = int(input(\"Choose scaling ->[0,1,2,3] = [2,4,8,16] boxsize\" ))\n",
    "    start = time.time()   #start time here for just to compare boxcount performance, everything before is preprocessing \n",
    "    #chosenscaling = 0  #   s 0 = bz 2,    s 1 = bz 4,    s 2 = bz 8,   s 3 = bz 16\n",
    "    #0 detects little edges  s3 just detects coarse edges\n",
    "    maxvalue = 256 \n",
    "    BoxCountR_SpacialLac_map = spacialBoxcount(ChosenImage, chosenscaling,maxvalue)\n",
    "    end = time.time()\n",
    "\n",
    "    timethisround = end-start\n",
    "    \n",
    "    print(timethisround,\" seconds passed for generating edgedetection map\")\n",
    "    BCRmap , Lakmap = BoxCountR_SpacialLac_map\n",
    "    \n",
    "    #set element-wise to True,  where element is over threshold\n",
    "    #threshold = np.max(Lakmap)/2.0\n",
    "    #Lakmap = Lakmap >= threshold\n",
    "    showNPArrayAsImage(Lakmap, \"Chosen Edgedetection Picture\", \"gray\")\n",
    "\n",
    "    #spacialboxcount\n",
    "    # get lacmap \n",
    "    pass\n",
    "\n",
    "\n",
    "youwanttoedgedetect = input(\"Do you want edgedetect the chosen picture? \\n y/n\")\n",
    "\n",
    "if youwanttoedgedetect == \"y\":\n",
    "    edgedectecion_with(pictureINquestion)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Multi-label/-task learning with deep convolutional neural networks\n",
    "\n",
    "Boxcounting like in paragraph 3.3.1 is a sequential task, which could be parallelized through utilizing a single convolutional neural network to calculate every resulting array specified in the multithreaded boxcounting function. The input of the convolutional neural network is a 2D array like the input picture in the cpu based boxcounting algorithm. The outputs of the network are the spacial boxcount ratios and lacunaritys to their respective scaling.\n",
    "\n",
    "### 3.5.1 Problems and solutions\n",
    "\n",
    "#### 3.5.1.1  Problem of different sized input shapes\n",
    "Due to a technical formality all input arrays to the network need to be the same size.\n",
    "To counter this problem, the incoming picture is going to be chunked into same sized arrays. Since common picture resolutions are mostly divisible by 2 and the chunks can be concatenated again after chunking, a reasonable picture size of 128x128 pixel was chosen.\n",
    "\n",
    " \n",
    "#### 3.5.1.2 Helper functions :\n",
    "The python script utilizes an argumentparser, which initiates an object containing all chosen options. To stay consistent with the code a option class object was initialized.\n",
    "In case there are chunks, which have a different sized shape, the functions reshape_Data and pad check for different sizes and pad the missing values with zeros.\n",
    "If you want to rebuild the training an testing datasets a helper function is needed to delete old datasets.\n",
    "To automatically set the device to cpu or gpu for pytorch, the helper function get device is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables---------------------------------------------------\n",
    "verbosity = False\n",
    "ChunkLenght = 128  # The picture will be hacked into pieces of chosen Size -> more Datapoints, less Ram, ...\n",
    "\n",
    "maxIndexX, maxIndexY = ChunkLenght, ChunkLenght\n",
    "shape = (maxIndexX, maxIndexY )\n",
    "\n",
    "#BOXCOUNT INIT\n",
    "Boxsize=[2,4,8,16,32,64,128]    #,256,512,1024]\n",
    "iteration = 0\n",
    "#os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "# Create a option object to store all variables\n",
    "class OptionObject:\n",
    "  def __init__(self, n_epochs, batch_size, img_size, channels, learning_rate, b1, b2 ):\n",
    "    self.n_epochs = n_epochs\n",
    "    self.batch_size = batch_size\n",
    "    self.img_size = img_size\n",
    "    self.lr = learning_rate\n",
    "    self.b1 = b1   #first order momentum of gradient decay\n",
    "    self.b2 = b2   #second order momentum of gradient decay\n",
    "    self.channels = channels\n",
    "    self.n_cpu = 0\n",
    "    \n",
    "#self, n_epochs, batch_size, img_size, channels, learning_rate, b1, b2\n",
    "opt = OptionObject(100, 32, ChunkLenght, 1 , 0.00002, 0.5, 0.8)\n",
    "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
    "\n",
    "\n",
    "\n",
    "#Source: [20] https://stackoverflow.com/questions/35751306/python-how-to-pad-numpy-array-with-zeros\n",
    "#@jit(nopython=False)  #,forceobj=True) # Set \"nopython\" mode for best performance, equivalent to @njit\n",
    "def pad(array, reference, offset):\n",
    "    \"\"\"\n",
    "    array: Array to be padded\n",
    "    reference: Reference array with the desired shape\n",
    "    offsets: list of offsets (number of elements must be equal to the dimension of the array)\n",
    "    \"\"\"\n",
    "    # Create an array of zeros with the reference shape\n",
    "    result = np.zeros(reference.shape)\n",
    "    # Create a list of slices from offset to offset + shape in each dimension\n",
    "    insertHere = [slice(offset[dim], offset[dim] + array.shape[dim]) for dim in range(array.ndim)]\n",
    "    # Insert the array in the result at the specified offsets\n",
    "    result[insertHere] = array\n",
    "    return result\n",
    "\n",
    "\n",
    "#If a picture/array is more little than the reference shape, than add zeros to the right and bottom with pad()-function to bring it into chunklenght x chunklenght\n",
    "def reshape_Data(PicNumPy,shape, original_shape):\n",
    "    #if shape is bigger then original, set new max and retry making data\n",
    "    reshape = (int(original_shape[0]),int(original_shape[1]) )\n",
    "    if verbosity:\n",
    "        print(\"reshaping, cause shape and original shape are\", shape, original_shape)\n",
    "        print(\"reshape\",reshape )\n",
    "        print(\"PicNumPy shape\",PicNumPy.shape)\n",
    "    ### can add offset; so that pict can be centered\n",
    "    offset = [0,0,0]\n",
    "    PicNumPy = pad(PicNumPy,np.zeros(reshape),offset )\n",
    "    return PicNumPy\n",
    "\n",
    "\n",
    "#just functions via jupyter notebook with !command\n",
    "def delete_dataset_from_last_time(FileParentPath):\n",
    "    really = input(\"-->(y/n):  Do you want to delete the old Dataset? \\n BE CARFUL: function can remove whole directorys, so dont change the Fileparentpath\")\n",
    "    \n",
    "    \n",
    "    if really ==\"y\":\n",
    "        OldDatasetSaveplace = FileParentPath+\"/Datasets/test/\"\n",
    "        try:\n",
    "            os.rmdir(OldDatasetSaveplace)\n",
    "            os.mkdir(OldDatasetSaveplace)\n",
    "            os.mkdir(OldDatasetSaveplace+\"/features/\")\n",
    "            os.mkdir(OldDatasetSaveplace+\"/labels/\")\n",
    "        except OSError:\n",
    "            print(\"Deleting old test dataset failed\")\n",
    "            PrintException()\n",
    "        else:\n",
    "            print(\"Old test dataset deleted!\")\n",
    "        \n",
    "        #!rm -rf OldDatasetSaveplace\n",
    "        #!mkdir OldDatasetSaveplace\n",
    "        #!mkdir OldDatasetSaveplace +\"/features/\"\n",
    "        #!mkdir OldDatasetSaveplace +\"/labels/\"\n",
    "\n",
    "\n",
    "        OldDatasetSaveplace = FileParentPath+\"/Datasets/train/\"\n",
    "        try:\n",
    "            os.rmdir(OldDatasetSaveplace)\n",
    "            os.mkdir(OldDatasetSaveplace)\n",
    "            os.mkdir(OldDatasetSaveplace+\"/features/\")\n",
    "            os.mkdir(OldDatasetSaveplace+\"/labels/\")\n",
    "        except OSError:\n",
    "            print(\"Deleting old train dataset failed\")        #!rm -rf OldDatasetSaveplace\n",
    "            PrintException()\n",
    "            input(\"Press any key to continue\")\n",
    "        else:\n",
    "            print(\"Old test dataset deleted!\")\n",
    "        \n",
    "        #!mkdir OldDatasetSaveplace\n",
    "        #!mkdir OldDatasetSaveplace +\"/features/\"\n",
    "        #!mkdir OldDatasetSaveplace +\"/labels/\"\n",
    "    else:\n",
    "        print(\"Continue without deleting the old dataset\")\n",
    "        input(\"Press any key to continue\")\n",
    "\n",
    "\n",
    "#Setting device to GPU/CPU \n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "\n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "print(\"Chosen Devide is\",device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2  Data preprosessing\n",
    "\n",
    "\n",
    "#### 3.5.2.1 Increased variance balancing\n",
    "In a balanced dataset the number of each class should be about equal to prevent the network from overfitting. This is accomplished by under- and oversampling, so to discard overrepresentative data or duplicate underrepresentative data. Since there are no prelabeled classes to this data and the output is matrix wise and quasicontinuous, balancing this data is based on the assumptions, that the fractal parameters are a quantitative measurement for the spacial dimensionality of an object and by that balancing can be achieved.\n",
    "The dataset is initiated with a base population of pictures and returns the sumed boxcount ratio and lacunarity for a chosen boxsize. A variance is calculated and by adding a new element to the dataset, the variance of the chosen values is in- or decreasing. With increasing variance, it is assumed, the new element is something unseen and increases the variance of the dataset. If the variance decreases, it is assumed, similar content already exists in the dataset and copies or slight alterations will more likely tend the neural network to overfit.\n",
    "\n",
    "\n",
    "To have some sort of controlling the aggressiveness of the train and test splitting, the variable precision is used to round the old and new variance. If the new variance is the same of bigger, add the current picture to the training dataset.If the variance is lower, add the current picture to the testing dataset. When the variable precision is zero, don't balance and just create a training dataset.\n",
    "\n",
    "\n",
    "#### 3.5.2.2 Make and split train and test data\n",
    "\n",
    "To be able to generate a dataset for machine learning purposes, some data preprocessing steps have to be executed, to learn the desired patterns accordingly.\n",
    "\n",
    "The dataset generation process iterates over the files of the specified path and loads the pictures as an array.\n",
    "To address pictures with multiple channels, like rgb, the channels are flattend by concatenating the arrays side by side from left to right.\n",
    "Due to a technical formality, the tensors in the machine learning model have to be consistent in size, so the loaded images are chunked into fixed grid areas with the size of 128² pixel.\n",
    "Neuronal networks can just work in the range of their activation function, so all features (images) and labels (spacial boxcounting results) have to be normalized from -1 to 1.\n",
    "\n",
    "The features and labels are indexed and saved in the subfolder named datasets, according to the train, test dataset split.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Data Balancing/Reshaping Part-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "'''\n",
    "The data has to be balanced in multiple ways to prevent overfitting.\n",
    "For example not all pictures can be used to train data. \n",
    "Binary classes can be balanced just by taking 50/50 balance for the training dataset.\n",
    "Cause the lables are the calculated arrays of a cpu driven program, \n",
    "there is just a continuum of output arrays for input arrays.\n",
    "'''\n",
    "verbosity = False\n",
    "precision = 1   # 0 dont balance, 1 balance light, ...9 balance fine; The finer, the more data will be discarded\n",
    "\n",
    "\n",
    "#if returns True, dataset stays balanced, so take into train-data, else pack into test set. \n",
    "#@jit(nopython=False)  #,forceobj=True) # Set \"nopython\" mode for best performance, equivalent to @njit\n",
    "def CalcPlacingcondition(DensityMap, sumBCR,sumLAK, precision, lastVariance, index):\n",
    "    #print(\"DensityMap\",DensityMap)\n",
    "    print(\"DensityMap.shape\",DensityMap.shape)\n",
    "\n",
    "    element = np.array([[sumBCR,sumLAK],])\n",
    "    \n",
    "    if index ==0:\n",
    "        combinedDensityMap = element     #init first element\n",
    "    else:\n",
    "        #concatenate the BCR and LAK from the current element to the \n",
    "        combinedDensityMap = np.concatenate((DensityMap,element),axis=0)\n",
    "\n",
    "    \n",
    "    if precision == 0:\n",
    "        placingcondition = True\n",
    "        DensityMap = combinedDensityMap\n",
    "        lastVariance = np.var(combinedDensityMap)\n",
    "    else:\n",
    "        if index <= 6:\n",
    "            #to populate the field, just add the first 6 elements\n",
    "            placingcondition = True\n",
    "\n",
    "            #cause element placingcondition is true, update the variances             \n",
    "            combinedVariance = np.var(combinedDensityMap)\n",
    "            lastVariance =  combinedVariance\n",
    "            print(\"populate with minimum Pop\")\n",
    "        else:\n",
    "            #calculate the Variance from this turn\n",
    "            combinedVariance = np.var(combinedDensityMap)\n",
    "\n",
    "            #if the rounded variance of this turn is more or the same of the variance last turn\n",
    "            if round(combinedVariance,precision) >= round(lastVariance,precision):    \n",
    "                placingcondition = True\n",
    "                #and update the last variance for next turn with the new value\n",
    "                lastVariance =  combinedVariance\n",
    "                DensityMap = combinedDensityMap\n",
    "            else:\n",
    "                #dont add this element to the training dataset but to the test dataset\n",
    "                placingcondition = False\n",
    "\n",
    "            if verbosity: print(\"index:\", index,\"    formerVariance,combinedVariance\",round(lastVariance,precision),round(combinedVariance,precision),\"so placing is\",placingcondition)    \n",
    "            #input()\n",
    "\n",
    "    return placingcondition, DensityMap, lastVariance\n",
    "\n",
    "\n",
    "\n",
    "def make_train_test_data(shape):\n",
    "    \n",
    "    Num_test = 0\n",
    "    Num_train = 0\n",
    "    firsttime = True\n",
    "\n",
    "    DensityMap= np.array([[0.0,0.0],])\n",
    "    lastVariance = 0.0\n",
    "    original_shape = shape\n",
    "\n",
    "    #For Visualizing  tqdm-progress bar\n",
    "    from tqdm import tqdm\n",
    "    pbar = tqdm(total=maxIndexY-1)\n",
    "    counter = 0\n",
    "    train_counter = 0\n",
    "    test_counter =0\n",
    "\n",
    "    from os import listdir\n",
    "    DataFolder = FileParentPath + \"/0Data/Images/\"\n",
    "    filelist = [f for f in listdir(DataFolder)]\n",
    "    #print(filelist)\n",
    "\n",
    "\n",
    "\n",
    "    from tqdm import tqdm\n",
    "    pbar = tqdm(total=len(filelist))\n",
    "\n",
    "    \n",
    "    n = 4 # werden wohl bis max 16 begrenzen # ist 4 da beim slicen  richitg wäre  boxsize[:4] oder [:-7]   \n",
    "\n",
    "    for index, filename in enumerate(filelist):\n",
    "        pbar.update(1)  #updates progressbar\n",
    "        counter +=1\n",
    "        try:   \n",
    "            filepath = DataFolder+ filename  #Load Image with Pillow\n",
    "            # Open the image\n",
    "            image = Image.open(filepath)\n",
    "            \n",
    "            # If the picture is in RGB or other multi-channel mode \n",
    "            #just seperate the channels and concatenate them from left to right\n",
    "            ChannleDimension = len(str(image.mode)) # grey -> 1 chan , rgb 3 channle\n",
    "            \n",
    "            if verbosity == True:\n",
    "                # summarize some details about the image\n",
    "                print(image.format,image.size)\n",
    "                print(image.mode)\n",
    "                #show the image\n",
    "                image.show()\n",
    "                print(\"ChannleDimension\",ChannleDimension)\n",
    "\n",
    "            channelcodierung = []\n",
    "            for channel in image.mode:\n",
    "                #FLATTEN EACH CHANNEL TO ONE  BY TILLING, cause cnn have to be consistent channles\n",
    "                #and if one rgb is in grayscale, then error\n",
    "                if verbosity: print(channel)\n",
    "                channelcodierung.append(channel)\n",
    "            \n",
    "            C1, C2, C3, C4, C5, C6 = None, None, None, None, None, None\n",
    "            channellist = [C1,C2,C3,C4,C5,C6]\n",
    "            croppedChannelList = channellist[0:ChannleDimension-1]\n",
    "            croppedChannelList = image.split()        \n",
    "            initEntry = None\n",
    "            stackedchannels = np.array(initEntry)\n",
    "            for idx, channel in enumerate(croppedChannelList):\n",
    "                PicNumpy = np.array(channel)\n",
    "                if verbosity == True:\n",
    "                    print(PicNumpy)\n",
    "                    print(PicNumpy.shape)\n",
    "\n",
    "                if idx == 0:\n",
    "                    stackedchannels = PicNumpy\n",
    "                else:\n",
    "                    stackedchannels = np.concatenate((stackedchannels,PicNumpy),axis=1)\n",
    "                \n",
    "            \n",
    "            if verbosity: print(stackedchannels.shape)\n",
    "            npOutputFile = stackedchannels\n",
    "\n",
    "            \n",
    "            #########################################################################\n",
    "            # MULTITHREAD BOXCOUNT LABLE EXTRACTION\n",
    "            BoxCountR_SpacialLac_map_Dict = MultithreadBoxcount(npOutputFile)\n",
    "\n",
    "            \n",
    "            ##### CALC PLACING CONDITION FOR EACH DATAPOINT(PICTURE)\n",
    "            maxiteration = 3 # cause boxsize 2,4,8,16 = 0,1,2,3 iteration # determines the maximum boxsize\n",
    "            #breaking it down to 2 values\n",
    "            sumBCR, sumLAK = BoxCountR_SpacialLac_map_Dict[1][0], BoxCountR_SpacialLac_map_Dict[1][1]             #BoxCountR_SpacialLac_map_Dict[4] #[0], BoxCountR_SpacialLac_map_Dict[4][1] \n",
    "            if verbosity: print(\"BCR,sumLAK  MAP before sum\", sumBCR,sumLAK)\n",
    "\n",
    "            sumBCR, sumLAK = np.sum(sumBCR), np.sum(sumLAK)\n",
    "            if verbosity: print(\"sumBCR,sumLAK after sum\", sumBCR,sumLAK)\n",
    "            \n",
    "            #Calc, if the next data in the dataset will balance it more or not\n",
    "            placingcondition, DensityMap, lastVariance = CalcPlacingcondition(DensityMap, sumBCR,sumLAK,precision,lastVariance, index)\n",
    "\n",
    "            maxChunkCount = (npOutputFile.shape[1]/ChunkLenght) * (npOutputFile.shape[0]/ChunkLenght)   #Chunks the picture is broken down into\n",
    "            #print(\"maxChunkCount\", maxChunkCount)\n",
    "            Chunks = [None] * int(np.ceil(maxChunkCount))     # round up the non full boxes, cause they will be reshaped by padding with zeros       \n",
    "            start = time.time()\n",
    "\n",
    "            BoxBoundriesY = [0,ChunkLenght]\n",
    "            BoxBoundriesX = [0,ChunkLenght]\n",
    "\n",
    "            iteration = 0       # is Boxsize 32 -> should be faster then more little boxsize\n",
    "            Boxsize=[2,4,8,16,32,64,128,256,512,1024]\n",
    "            scalingFaktor = 1.0 / float(Boxsize[iteration])\n",
    "            #If we take a sclice from the BCRmap/LAKmap, the boxboundries have to  be scaled for maintaining spacial dimensions across scaling with iteration and Boxsize\n",
    "            Scaled_BoxBoundriesY = [0,int(ChunkLenght*scalingFaktor)]\n",
    "            Scaled_BoxBoundriesX = [0,int(ChunkLenght*scalingFaktor)]\n",
    "\n",
    "\n",
    "            for i in range(len(Chunks)):\n",
    "\n",
    "                Chunks[i] = npOutputFile[BoxBoundriesY[0]:BoxBoundriesY[1],BoxBoundriesX[0]:BoxBoundriesX[1]] \n",
    "\n",
    "                CHUNKED_BoxCountR_SpacialLac_map_Dict = {}\n",
    "                CuttedBoxsizeList = Boxsize[:maxiteration+1]\n",
    "                if verbosity == True:\n",
    "                    print(\"Current box\",i,\"of all\",len(Chunks),\"boxes\")\n",
    "                    print(\"Boxboundries: X, Y :\" ,BoxBoundriesX,BoxBoundriesY)\n",
    "                    print(\"CuttedBoxsizeList\", CuttedBoxsizeList)\n",
    "                    print(\"Converting BCRmap,LAKmap into Chunked Form\")\n",
    "                    \n",
    "                for it , currentboxsize in enumerate(CuttedBoxsizeList):\n",
    "                    if verbosity: print(\"Iteration\", it, \" and currentBoxsize\", currentboxsize)\n",
    "                    \n",
    "                    scalingFaktor = 1.0 / float(currentboxsize)\n",
    "                    \n",
    "                    try:\n",
    "                        #calc Scaled BoxBoundriesY\n",
    "                        Scaled_BoxBoundriesY = [int(BoxBoundriesY[0]*scalingFaktor),int(BoxBoundriesY[1]*scalingFaktor)]\n",
    "\n",
    "                    except:\n",
    "                        PrintException()\n",
    "                        #Assuming devide by zero\n",
    "                        Scaled_BoxBoundriesY = [0,int(BoxBoundriesY[1]*scalingFaktor)]\n",
    "\n",
    "                    try:\n",
    "                        #calc Scaled BoxBoundriesX\n",
    "                        Scaled_BoxBoundriesX = [int(BoxBoundriesX[0]*scalingFaktor),int(BoxBoundriesX[1]*scalingFaktor)]\n",
    "\n",
    "                    except:\n",
    "                        PrintException()\n",
    "                        #Assuming devide by zero\n",
    "                        Scaled_BoxBoundriesX = [0,int(BoxBoundriesX[1]*scalingFaktor)]                       \n",
    "\n",
    "\n",
    "                    BCRmap, LAKmap = BoxCountR_SpacialLac_map_Dict[it]\n",
    "                    \n",
    "                    chunked_BCRmap = BCRmap[Scaled_BoxBoundriesY[0]:Scaled_BoxBoundriesY[1],Scaled_BoxBoundriesX[0]:Scaled_BoxBoundriesX[1]] \n",
    "                    chunked_LAKmap = LAKmap[Scaled_BoxBoundriesY[0]:Scaled_BoxBoundriesY[1],Scaled_BoxBoundriesX[0]:Scaled_BoxBoundriesX[1]] \n",
    "                    \n",
    "                    #SCALING----------------------------\n",
    "                    #Scale the values of the Arrays in a gaussian distrubution with mean 0 and diviation 1?!?!?!\n",
    "                    #chunked_BCRmap, chunked_LAKmap = preprocessing.scale(chunked_BCRmap) , preprocessing.scale(chunked_LAKmap) \n",
    "\n",
    "                    '''\n",
    "                    ATTENTION SCALING DEACTIVATED\n",
    "                    '''\n",
    "                    \n",
    "                    #Normalize the Values betweeen -1...1----------------------------\n",
    "                    chunked_BCRmap, chunked_LAKmap = preprocessing.normalize(chunked_BCRmap, norm='l1')  , preprocessing.normalize(chunked_LAKmap, norm='l1')  \n",
    "\n",
    "\n",
    "                    if verbosity == True:\n",
    "                        showNPArrayAsImage(Chunks[i], \"Current Chunk\", \"gray\")\n",
    "                        print(\"chunked_BCRmap\",chunked_BCRmap)\n",
    "                        print(\"chunked_LAKmap\",chunked_LAKmap)\n",
    "                        showNPArrayAsImage(chunked_BCRmap, \"chunked_BCRmap\", \"gray\")\n",
    "                        showNPArrayAsImage(chunked_LAKmap, \"LAKmap\", \"gray\")                    \n",
    "                    \n",
    "                    #index the BCR /LAK map to the right size \n",
    "                    CHUNKED_BoxCountR_SpacialLac_map_Dict[it] = [chunked_BCRmap, chunked_LAKmap]\n",
    "\n",
    "\n",
    "                #Scale Dataset : Scaled data has zero mean and unit variance\n",
    "                #Chunks[i]= preprocessing.scale(Chunks[i])\n",
    "                \n",
    "                '''\n",
    "                ATTENTION SCALING DEACTIVATED\n",
    "                '''\n",
    "                \n",
    "                \n",
    "                #Normalizing ARRAY  from 0...255 to -1...+1\n",
    "                Chunks[i] = preprocessing.normalize(Chunks[i], norm='l1')        \n",
    "                Chunkshape = Chunks[i].shape\n",
    "\n",
    "                if BoxBoundriesX[1] > npOutputFile.shape[1]  or BoxBoundriesY[1] > npOutputFile.shape[0]:\n",
    "                    if verbosity: print(\"Chunkshape and shape are Different... reshaping\")\n",
    "                    Chunks[i] =  reshape_Data(Chunks[i], Chunkshape, shape)\n",
    "                    continue\n",
    "\n",
    "                assert Chunks[i].shape == original_shape\n",
    "\n",
    "                newshape = ( 1,int(original_shape[0]),int(original_shape[1]) )\n",
    "                Chunks[i] = np.reshape(Chunks[i], newshape)\n",
    "\n",
    "                #saving test or Train image and label\n",
    "                feature =  Chunks[i]\n",
    "                label =  [np.array(CHUNKED_BoxCountR_SpacialLac_map_Dict[0]) , np.array(CHUNKED_BoxCountR_SpacialLac_map_Dict[1]) , np.array(CHUNKED_BoxCountR_SpacialLac_map_Dict[2]) , np.array(CHUNKED_BoxCountR_SpacialLac_map_Dict[3]) ]\n",
    "                \n",
    "                if verbosity == True:\n",
    "                    print(\"feature\",feature)\n",
    "                    print(\"label\",label)\n",
    "\n",
    "                if placingcondition == True:\n",
    "                    if verbosity: print(\"Placingcondition is true, Append Chunk to dataset\")\n",
    "                    #saveplace\n",
    "                    trainsaveplace = FileParentPath+\"/Datasets/train/\"\n",
    "                    #saving image\n",
    "                    imagesaveplace = trainsaveplace+ \"/features/\"+\"Feature\"+ str(Num_train)\n",
    "                    np.save(imagesaveplace, feature)\n",
    "                    #saving label\n",
    "                    labelsaveplace = trainsaveplace+ \"/labels/\"+\"label\"+ str(Num_train)\n",
    "                    #CANT save List with different sized np arrays with np.save -> use pickle as workaround\n",
    "                    pickle.dump(label,open(labelsaveplace,\"wb\"))\n",
    "                    Num_train +=1\n",
    "                        \n",
    "                else:\n",
    "                    testsaveplace = FileParentPath+\"/Datasets/test/\"\n",
    "                    #saving image\n",
    "                    imagesaveplace = testsaveplace+ \"/features/\"+\"Feature\"+ str(Num_test)\n",
    "                    np.save(imagesaveplace, feature)\n",
    "                    #saving label\n",
    "                    labelsaveplace = testsaveplace+ \"/labels/\"+\"label\"+ str(Num_test)\n",
    "                    #np.save(labelsaveplace, label)\n",
    "                    #CANT save List with different sized np arrays with np.save -> use pickle as workaround\n",
    "                    pickle.dump(label,open(labelsaveplace,\"wb\"))\n",
    "                    Num_test +=1\n",
    "\n",
    "\n",
    "\n",
    "                #After this Chunk set the new Borders of the new chunk for next turn\n",
    "\n",
    "                if BoxBoundriesX[1] < npOutputFile.shape[1]:\n",
    "\n",
    "                    BoxBoundriesX[0] =BoxBoundriesX[0] + maxIndexX\n",
    "                    BoxBoundriesX[1] = BoxBoundriesX[1] + maxIndexX\n",
    "                    if verbosity == True: \n",
    "                        print(\"Move box into x direction\")\n",
    "                        print(\"BoxBoundriesX\", BoxBoundriesX)\n",
    "                else:\n",
    "                    if verbosity == True:\n",
    "                        print(BoxBoundriesY,\"BoxBoundriesY\") \n",
    "                        print(\"move box into starting position in x-direction\")\n",
    "                        print(\"move box into ydirection\")\n",
    "                    BoxBoundriesX[0]=0\n",
    "                    BoxBoundriesX[1]=maxIndexX\n",
    "                    BoxBoundriesY[0]+=maxIndexY\n",
    "                    BoxBoundriesY[1]+=maxIndexY\n",
    "                    \n",
    "            if verbosity: input(\"Press any key for next File\")\n",
    "\n",
    "\n",
    "            end = time.time()     \n",
    "            print(round(end,1) - round(start,1), \"seconds passed for chunking and Make Train Data for 1 File\")\n",
    "\n",
    "        except :\n",
    "            PrintException()\n",
    "            input()\n",
    "            pass\n",
    "    \n",
    "    pbar.close()        #close the percentage bar cause all pictures have been processed\n",
    "\n",
    "    if verbosity:\n",
    "        #To evaluate, if balancing happened  show figure of all BCR/LAKS of the training dataset\n",
    "        x,y = np.array([]) , np.array([])\n",
    "        for Koordinate in DensityMap:\n",
    "            x,y = np.append(x,Koordinate[0]) , np.append(y,Koordinate[1])\n",
    "\n",
    "        # Plot\n",
    "        plt.scatter(x, y,s=1, alpha=0.33)\n",
    "        plt.title('Lacunarity-Boxcountratio Diagramm')\n",
    "        plt.xlabel('sumBCR')\n",
    "        plt.ylabel('MeanLAK')\n",
    "        plt.show()\n",
    "\n",
    "    print(\"Num_train\",Num_train ,\"Num_test\",Num_test)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#If rebuild  data == True, take the chosen DataFOLDER and create a train and test Dataset \n",
    "youwanttorebuild = input(\"y/N   Do you want to rebuild the machine learning dataset? \\n Just has to be executed once.\")\n",
    "\n",
    "if youwanttorebuild == \"y\":\n",
    "    REBUILD_DATA = True\n",
    "elif youwanttorebuild == \"\" or youwanttorebuild == \"n\" or youwanttorebuild == \"N\":\n",
    "    REBUILD_DATA = False  # set to true to run once, then back to false unless you want to change something in your training data.\n",
    "\n",
    "    \n",
    "if REBUILD_DATA == True:\n",
    "    delete_dataset_from_last_time(FileParentPath)\n",
    "    make_train_test_data(shape)\n",
    "    \n",
    "#REBUILDING/Balancing DATA DONE ---------------------------------------------------------------------------------------------\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3 Define custom multi label dataset for pytorch\n",
    "\n",
    "The multi label approach needs to define a custom dataset, using the pytorch dataloader. It automatically handels multiprocessing to keep hardware utilization high during training. The training and testing dataset is generated from the files, which are saved by the data preprocessing function (3.5.5.2) in the subfolder datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create COUSTOM Pytorch DATASET with features and labels----------------------------------------------------------------------------\n",
    "# Source: [21] https://stackoverflow.com/questions/56774582/adding-custom-labels-to-pytorch-dataloader-dataset-does-not-work-for-custom-data\n",
    "try:\n",
    "    import platform\n",
    "    Operating_system = platform.system()\n",
    "    print(Operating_system)\n",
    "    if Operating_system == 'Windows':\n",
    "        print(\"Windows detected, dataloader multiprocessing not avaiable. Set n_cpu to 0 \")\n",
    "        opt.n_cpu = 0\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "\n",
    "    class Dataset:\n",
    "        def __init__(self, root):\n",
    "            \"\"\"Init function should not do any heavy lifting, but\n",
    "                must initialize how many items are availabel in this data set.\n",
    "            \"\"\"\n",
    "            self.featurepath = root + \"/features\"\n",
    "            self.labelpath = root + \"/labels\"\n",
    "\n",
    "            self.ROOT = root\n",
    "            self.featurelist = [f for f in listdir(self.featurepath) if isfile(join(self.featurepath, f))]\n",
    "            self.labellist = [f for f in listdir(self.labelpath) if isfile(join(self.labelpath, f))]\n",
    "\n",
    "        def __len__(self):\n",
    "            \"\"\"return number of points in our dataset\"\"\"\n",
    "            return len(self.featurelist)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            \"\"\" Here we have to return the item requested by `idx`\n",
    "                The PyTorch DataLoader class will use this method to make an iterable for\n",
    "                our training or validation loop.\n",
    "            \"\"\"\n",
    "            imagepath =   self.featurepath+\"/\"+ \"Feature\" +str(idx)+\".npy\"\n",
    "            img = np.load(imagepath)\n",
    "            labelpath =   self.labelpath+\"/\"+ \"label\"+str(idx)\n",
    "            #Below is to read and retrieve its contents, rb-read binary\n",
    "            with open(labelpath, \"rb\") as f:\n",
    "                label = pickle.load(f) \n",
    "                labels_2 = np.array(label[0])\n",
    "                labels_4 = np.array(label[1])\n",
    "                labels_8 = np.array(label[2])\n",
    "                labels_16 = np.array(label[3])\n",
    "            return img, labels_2 , labels_4 , labels_8, labels_16\n",
    "\n",
    "    #And now, you can create an instance of this class as,\n",
    "    trainDatasetSaveplace = FileParentPath + \"/Datasets/train\"\n",
    "    trainDataset = Dataset(trainDatasetSaveplace)\n",
    "    #Now, you can instantiate the DataLoader:\n",
    "    trainDataloader = DataLoader(trainDataset, batch_size=opt.batch_size, shuffle=True, num_workers=opt.n_cpu, drop_last=True)\n",
    "    dataiter = iter(trainDataloader)\n",
    "    trainDataset = dataiter.next()\n",
    "    trainDataset  = transforms.ToTensor()\n",
    "\n",
    "    #DEFINING TEST DATA LOADER FOR TESTINGs\n",
    "\n",
    "    testDatasetSaveplace = FileParentPath + \"/Datasets/test\"\n",
    "    testDataset = Dataset(testDatasetSaveplace)\n",
    "    testDataLoader = DataLoader(testDataset, batch_size=opt.batch_size, shuffle=True, num_workers=opt.n_cpu, drop_last=True )\n",
    "    #This will create batches of your data that you can access as:\n",
    "    testiter=  iter(testDataLoader)\n",
    "    testDataset = testiter.next()\n",
    "    testDataset  = transforms.ToTensor()\n",
    "\n",
    "\n",
    "    #####################################################################################################################\n",
    "    #       DATA COMPLETE       ->     NOW MACHINE LEARNING PART\n",
    "\n",
    "except:\n",
    "    PrintException()\n",
    "    print(\"Did you rebuild the train test data? Please check\")\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.4 Defining network architecture\n",
    "\n",
    "While the cpu based spacial boxcounting algorithm has to be executed for every boxsize in a different thread, there may be many similar or equal computation steps between threads, which could be saved.\n",
    "A single input multi-channel/-label output machine learning model to compute everything in one forward pass is declared.\n",
    "The class \"BoxcountEncoder\" is defined by a integer-based layer discription, which is passed to it at the initialization step to generate a convolutional neural network.\n",
    "The network gets a batch of arrays as input. \n",
    "At each convolutional layer the picture is scaled down by the factor of 2, to reduce the size in x- and y-direction with the help of a convolutional layer with the kernel size and a stride of 2x2.\n",
    "The network receives one input channel due to the grayscale 8-bit image. The channels of the hidden layers can be chosen arbitrarily and are optimizable hyperparameters. A schematic of this neural network architecture is shown in figure 9.\n",
    "\n",
    "Because the hidden layers have way more than 2 channels, each layer and so forth downscaling an output branch is added. This output branch utilizes a 1x1 conv layer with two output channels, to compare the network output against the spacial boxcounting ratio and lacunarity arrays in a pixelwise lossfunction.\n",
    "The internal activation functions are composed of leaky rectified linear units, named relu for fast convergence.\n",
    "The output layers are activated by a hyperbolic tangent function, which allows for scaled input data with mean of zero and standard deviation of one. Due to the fact that scaling changes the data distribution within the array and we just want to quantitatively characterize the containing original data, it was disabled, but the hyperbolic tangent function is still in place.\n",
    "If scaling is disabled the sigmoid activation function is another option to apply to the output layers ranging from 0 to 1, because 8-bit images are only positive bits ranging from 0 to 255.\n",
    "The layer discripton also allows batch-normalization layers, which effects were not used or tested yet.\n",
    "\n",
    "\n",
    "\n",
    "![image info](https://raw.githubusercontent.com/ollimacp/spacial-boxcounting-cpu-gpu/main/0Data/Document_images/networkarch2.png)\n",
    "\n",
    "Figure 9: Multi label output model architecture.   \n",
    "Source: http://alexlenail.me/NN-SVG/AlexNet.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbosity = False\n",
    "#INIT BoxcountNetParams as empty Dict\n",
    "BoxCountParameter = {}\n",
    "\n",
    "#The BoxCountEncoder takes the image and calculates the boxcountratios and the Lakcountmaps for each iteration/boxsize/scale and returns it.\n",
    "\n",
    "class BoxCountEncoder(nn.Module):\n",
    "    def __init__(self,Parameter):\n",
    "        super(BoxCountEncoder, self).__init__()\n",
    "        #Boxcount EncoderLayer<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "        self.LayerDiscription = Parameter['BoxCountLayerDiscription']   #\n",
    "        self.input_shape = Parameter['input_shape']\n",
    "        self.LayerCount = len(self.LayerDiscription)\n",
    "        self.Layers = nn.ModuleList() \n",
    "        self.OutputLayerIndexList = Parameter['OutputLayerIndexList']\n",
    "        if verbosity == True:\n",
    "            print(\"self.OutputLayerIndexList\", self.OutputLayerIndexList)\n",
    "\n",
    "        #Throughput=[]   #list of layercount for Batchnormlayer\n",
    "        #ATTENTION  ENHANCER BUILDS NETWORK BACKWARDS AND IN AND OUT ARE ALSO SWITCHED\n",
    "        for i in range(self.LayerCount):        #iterate forwards\n",
    "            IN,OUT,Kx, Ky,Sx,Sy,Px,Py,BN = self.LayerDiscription[i]\n",
    "            if verbosity: print(\"Layer\",i,\" with Parameters\", IN,OUT,Kx, Ky,Sx,Sy,Px,Py,BN)\n",
    "            self.Layers.append(nn.Conv2d(IN,OUT, kernel_size=(Kx, Ky), stride=(Sx, Sy), padding=(Px, Py)) )      #Attention Compressor INOUT NOrmal\n",
    "            \n",
    "            #if this is an output layer, then use tanH instead of relu to prevent jumps for values around zero\n",
    "            # tanh also allows scaled data, which it's mean is around zero and standard devitation of one\n",
    "            if OUT==2 and  Kx==1 and Ky==1 and Sx==1 and Sy ==1 or  int(i) == int(self.LayerCount)-1: \n",
    "                if verbosity: print(\"Output Layer found\")\n",
    "                #self.Layers.append(nn.Sigmoid())\n",
    "                self.Layers.append(nn.Tanh())\n",
    "                #Cause tanh is another layer it has to be in  self.OutputLayerIndexList, so it dosent connect to x but branched out to y\n",
    "            else:\n",
    "                #Just use LeakyReLU for fast convergence\n",
    "                self.Layers.append(nn.LeakyReLU(inplace = True))\n",
    "   \n",
    "            if BN ==1:\n",
    "                self.Layers.append( nn.BatchNorm2d(OUT, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) )      #Attention Compressor INOUT NOrmal\n",
    "                #Throughput.append(OUT)      \n",
    "\n",
    "        if verbosity: print(\"self.input_shape\",self.input_shape)\n",
    "        print(self.Layers)\n",
    "        print(\"-------------INIT DONE ------------------ \\n \")\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        output2, output4, output8, output16 = None, None, None, None\n",
    "        OutputList = [output2, output4, output8, output16]\n",
    "        outputindex = 0\n",
    "        for i, layer in enumerate(self.Layers):        #iterate forwards\n",
    "            #IN,OUT, Kx, Ky,Sx,Sy,Px,Py,BN = self.LayerDiscription[i]\n",
    "\n",
    "            if i in self.OutputLayerIndexList:      #If this is a Output layer\n",
    "                out = self.Layers[i](x)     # create branch and dont overwrite x\n",
    "                #prints commented out, cause foreward will be executed millions of times\n",
    "                #print(\"Create Branch\")\n",
    "            elif i-1 in self.OutputLayerIndexList:      #If this is a Output layer ACTIVATION FUNCTION (tanh)\n",
    "                out = self.Layers[i](out)     # ACtivate out with act. fct\n",
    "                OutputList[outputindex] = out       # set value for each output-layer / scale \n",
    "                #print(\"Activate Branch for output\",outputindex)                \n",
    "                outputindex +=1 \n",
    "            else:\n",
    "                x = self.Layers[i](x)\n",
    "                #print(\"Append layer to Main Branch\")\n",
    "\n",
    "        return OutputList[0] , OutputList[1] , OutputList[2] , OutputList[3]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.6 Define training and saving strategy for the convolutional neural network model\n",
    "\n",
    "Training convolutional neural networks consumes a lot of computational power and time to converge against zero in a given loss function. There also are many hyperparameters and a model saving strategy to choose, because things might go wrong in many ways, so saving the progress occasionally is a important part, when the training can take several days of computation.\n",
    "\n",
    "To tackle the hyperparameter optimization, the python library hyperopt was applied to the training part in form of the following training function. The training function is given a hyperparameter-space dictionary and the boxcount encoder class to generate a neural network. The loss function is defined by the pixelwise loss between the net generated output and the real cpu-calculated labels. The lossfunction of each boxsize is multiplied by a chosen fraction to gain control for weighing each boxsize. The weighed lossfunctions are sumed up to the general lossfunction and backpropagation is applied over the complete model. The chosen optimizer is adam with the learning rate, the first and second moment of learning rate decay.\n",
    "\n",
    "The saving of new models will be executed, if the loss function of the current model is lower than the previous loss function. At this point the model has to be saved in 2 files, containing the network parameters, which are able to generate the chosen model architecture and the models weights and biases in form of a state dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_Best_Loss = None\n",
    "Loss_Now = None\n",
    "\n",
    "def TrainSpacialBoxcount_with(HyperparameterAndENCODERCLASS):\n",
    "    HyperParameterspace, BoxCountEncoder =  HyperparameterAndENCODERCLASS \n",
    "\n",
    "    global previous_Best_Loss, Loss_Now\n",
    "    #BoxCountEncoder = None\n",
    "\n",
    "    #INIT VARIABLES\n",
    "    opt.n_epochs = HyperParameterspace['n_epochs']\n",
    "    opt.batch_size = HyperParameterspace['batch_size']\n",
    "    opt.lr = HyperParameterspace['lr']\n",
    "    opt.b1 = HyperParameterspace['b1']\n",
    "    opt.b2 = HyperParameterspace['b2']\n",
    "\n",
    "    #BoxCountLayerDiscription\n",
    "    #self.BoxcountRatioConv = nn.Conv2d(3, 16, (self.BoxsizeX,BoxsizeY), (len(self.BoxsizeX), len(self.BoxsizeY) ), padding=0) \n",
    "    #self.LACcountConv = nn.Conv2d(3, 16, (self.BoxsizeX,self.BoxsizeY), (len(self.BoxsizeX), len(self.BoxsizeY) ), padding=0) \n",
    "    Boxsize=[2,4,8,16,32,64,128,256,512,1024]\n",
    "\n",
    "    #Channles\n",
    "    IN, OUTCOM = 1 , 2      #Channels 2, cause output is BCRmap and LAKmap, one is derived from the other\n",
    "    Inter1, Inter2, Inter3    = HyperParameterspace['Inter1'], HyperParameterspace['Inter2'], HyperParameterspace['Inter3']          # Hyperoptimization here\n",
    "    #Kernelsize in X/Y resprective layer is 2, cause...\n",
    "    Kx1, Kx2, Kx3, Kx4              = 2,2,2,2       \n",
    "    Ky1, Ky2, Ky3, Ky4              = 2,2,2,2\n",
    "    # ...with a stride of 2 the picture is getting halfed in size, exacly like the boxcounting with bigger boxsizes , but in cpu version the ori bz overlap one pixel, which here is not checkk\n",
    "    Sx1, Sx2, Sx3, Sx4              = 2, 2, 2, 2\n",
    "    Sy1, Sy2, Sy3, Sy4              = 2, 2, 2, 2\n",
    "    #padding should be 0, cause every picture is same size and all the kernels fit perfectly\n",
    "    Px1, Px2, Px3, Px4              = 0,0,0,0\n",
    "    Py1, Py2, Py3, Py4              = 0,0,0,0\n",
    "    #Batchnorm is not needed, causewe want to focus just on the convolution calculation  and dont want to alter the image/ entry arrays in any unknown form..\n",
    "    BN1, BN2, BN3, BN4              = 0,0,0,0\n",
    "\n",
    "    #Intermediate OutputLayer ... Cause every Filter of a Convulution  is described within the Channels in the hidden layers and we want to output the BCR and LAK like like the cpu version...\n",
    "    # we have to generate an output with a 1x1 = KxS conv with x Chan input and 2 Chan Output for calcing the loss\n",
    "\n",
    "    BoxCountLayerDiscription = [    [IN,    Inter1,Kx1, Ky1,Sx1,Sy1,Px1,Py1,BN1],   #input layer\n",
    "                                    [Inter1,OUTCOM ,1, 1,1,1,0,0,0],                # output layer for first iteration (Boxsize 2)\n",
    "\n",
    "                                    [Inter1,Inter2,Kx2, Ky2,Sx2,Sy2,Px2,Py2,BN2],\n",
    "                                    [Inter2,OUTCOM ,1, 1,1,1,0,0,0],                # output layer for second iteration (Boxsize 4)\n",
    "        \n",
    "                                    [Inter2,Inter3,Kx3, Ky3,Sx3,Sy3,Px3,Py3,BN3],\n",
    "                                    [Inter3,OUTCOM ,1, 1,1,1,0,0,0],                # output layer for third iteration (Boxsize 8)\n",
    "\n",
    "                                    [Inter3,OUTCOM,Kx4, Ky4,Sx4,Sy4,Px4,Py4,BN4],   #last ouput layer\n",
    "                                            ]                       # [Inter3,OUTCOM ,1, 1,1,1,0,0,0],                # output layer for 4th iteration (Boxsize 16)\n",
    "\n",
    "    input_shape = (opt.batch_size,1, ChunkLenght,ChunkLenght)\n",
    "\n",
    "    OutputLayerIndexList = [2,6,10,12]        # Cause the intermediate output layers are branched out from the main flowchart\n",
    "\n",
    "    BoxCountNetParameters = {'BoxCountLayerDiscription': BoxCountLayerDiscription, 'input_shape': input_shape, 'OutputLayerIndexList': OutputLayerIndexList}\n",
    "\n",
    "\n",
    "    Modelname =  \"n_epochs_\" + str(round(opt.n_epochs,3)) \n",
    "    Modelname += \"_batch-size_\" + str(round(opt.batch_size,3))   \n",
    "    Modelname += \"_learning-rate_\" + str(round(opt.lr,3))\n",
    "    Modelname += \"_beta-decay_\" + str(round(opt.b1,3)) +\"_\" + str(round(opt.b2,3))\n",
    "    #Modelname += \"_Scalefactors_\" + str(round(Scalefactor_2,3)) +\"_\" + str(round(Scalefactor_4,3)) +\"_\" + str(round(Scalefactor_8,3))\n",
    "\n",
    "    # -----------------\n",
    "    #  Train_BoxcountingCONV\n",
    "    # -----------------\n",
    "    #define Loss\n",
    "    pixelwise_loss = torch.nn.L1Loss()\n",
    "\n",
    "    #Init BoxcountEncoder\n",
    "    BoxCountEncoder = BoxCountEncoder(BoxCountNetParameters)\n",
    "    \n",
    "    BoxCountEncoder.to(device)\n",
    "    pixelwise_loss.to(device)\n",
    "\n",
    "    # Optimizers\n",
    "    optimizer_BC = torch.optim.Adam(BoxCountEncoder.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "    if device==\"cuda\":\n",
    "        Tensor = torch.cuda.FloatTensor \n",
    "\n",
    "    else:\n",
    "        Tensor = torch.FloatTensor\n",
    "\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    # ----------\n",
    "    #  Training\n",
    "    # ----------\n",
    "\n",
    "    epochs =range(opt.n_epochs)\n",
    "\n",
    "    print(\"Model: \",Modelname)\n",
    "\n",
    "    for epoch in epochs:\n",
    "        if verbosity: print(\"epoch \",str(epoch), \"of\", str(opt.n_epochs) ) \n",
    "            \n",
    "        for i, (images, labels_2, labels_4, labels_8, labels_16 ) in enumerate(trainDataloader):\n",
    "            #real_labels_2, real_labels_4, real_labels_8, real_labels_16 = labels\n",
    "            \n",
    "            if verbosity: print(\"Nr\",str(i) ,\"of\", str(len(trainDataloader))) \n",
    "            real_labels_2 = Variable(labels_2.type(Tensor))\n",
    "            real_labels_2.to(device)\n",
    "\n",
    "            real_labels_4 = Variable(labels_4.type(Tensor))\n",
    "            real_labels_4.to(device)\n",
    "\n",
    "            real_labels_8 = Variable(labels_8.type(Tensor))\n",
    "            real_labels_8.to(device)\n",
    "\n",
    "            real_labels_16 = Variable(labels_16.type(Tensor))\n",
    "            real_labels_16.to(device)\n",
    "\n",
    "            # Configure input\n",
    "            real_imgs = Variable(images.type(Tensor))\n",
    "            real_imgs.to(device)\n",
    "\n",
    "            optimizer_BC.zero_grad()\n",
    "\n",
    "            BCR_LAK_map_2 , BCR_LAK_map_4 , BCR_LAK_map_8 , BCR_LAK_map_16 = BoxCountEncoder(real_imgs)\n",
    "\n",
    "\n",
    "            BCR_LAK_map_2_loss  = pixelwise_loss(BCR_LAK_map_2, real_labels_2)\n",
    "            BCR_LAK_map_4_loss = pixelwise_loss(BCR_LAK_map_4, real_labels_4)\n",
    "            BCR_LAK_map_8_loss = pixelwise_loss(BCR_LAK_map_8, real_labels_8)\n",
    "            BCR_LAK_map_16_loss = pixelwise_loss(BCR_LAK_map_16, real_labels_16)\n",
    "            \n",
    "            Scalefactor_2 , Scalefactor_4 , Scalefactor_8 , Scalefactor_16  =  0.25, 0.25, 0.25 , 0.25      # maybe optimiziing usage?!\n",
    "            BCR_LAK_loss =  Scalefactor_2 * BCR_LAK_map_2_loss + Scalefactor_4 * BCR_LAK_map_4_loss + Scalefactor_8 * BCR_LAK_map_8_loss + Scalefactor_16 * BCR_LAK_map_16_loss\n",
    "            if verbosity: print(\"loss: BCR_LAK_loss\",BCR_LAK_loss) \n",
    "\n",
    "            #input()\n",
    "            BCR_LAK_loss.backward()\n",
    "            optimizer_BC.step()\n",
    "        '''\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [BC loss: %f]  \"\n",
    "            % (epoch, opt.n_epochs, i, len(trainDataloader), BCR_LAK_loss.item() )\n",
    "        )\n",
    "        '''\n",
    "\n",
    "    ### SAVE MODEL IF its better than 0something\n",
    "    if previous_Best_Loss == None:\n",
    "        previous_Best_Loss = BCR_LAK_loss.item()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "    Loss_Now = BCR_LAK_loss.item()\n",
    "    print(\"Best loss so far  :\", previous_Best_Loss)\n",
    "    print(\"loss of this model:\", Loss_Now)\n",
    "\n",
    "    if Loss_Now <= previous_Best_Loss:\n",
    "        #<= to save first model always and then just, when better model was found with LOWER LOSS \n",
    "        saveplace = FileParentPath\n",
    "        saveplace +=\"/models/\"\n",
    "        saveplace += \"Loss\" + str(round(BCR_LAK_loss.item(),3)) +\"---\"\n",
    "        saveplace += Modelname\n",
    "        NetParametersSaveplace = saveplace +\".netparams\"\n",
    "        with open(NetParametersSaveplace, \"wb\") as f:\n",
    "            pickle.dump(BoxCountNetParameters, f)\n",
    "        \n",
    "        saveplace += \".model\"\n",
    "        torch.save(BoxCountEncoder.state_dict(), saveplace)\n",
    "        #only update, when it was higher\n",
    "        print(\"Model Saved\")\n",
    "        previous_Best_Loss = Loss_Now\n",
    "\n",
    "    else:\n",
    "        print(\"Loss was higher/worse than previous best model\")\n",
    "\n",
    "    return {'loss': BCR_LAK_loss.item(), 'status': STATUS_OK}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.7 Training with hyperoptimization and progress saving\n",
    "\n",
    "To save occasional progress the trials object from the hyperparameteroptimization library can be saved and reloaded. The trials object contains the previous hyperparameters and their respective losses. The \"tpe suggest\" algorithm will choose the new hyperparameters, considering the content of the trials object.\n",
    "The hyperparameter optimization will be initialized at first by creating a new trials object, then train three times and then saves the trials object. After loading the saved trials object, it will be saved after every hyperparameter optimization step minimizing risk of losing progress. \n",
    "\n",
    "Hyperopt's parameter space is simply defined by a dictionary with its chosen parameters and are ranged binary, integer like or continuously by their respective functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source: [22] https://github.com/hyperopt/hyperopt/issues/267\n",
    "\n",
    "youwanttotrain = input(\"Do you want to train? Y/n\")\n",
    "\n",
    "if youwanttotrain == \"\" or youwanttotrain == \"y\" or youwanttotrain == \"Y\":\n",
    "    #To save trials object to pick up where you left\n",
    "    def run_trials(HyperParameterspace, Modelname):\n",
    "        #ATTENTION: If you want to begin training anew, then you have to delete the .hyperopt file\n",
    "        TrialsSaveplace = FileParentPath\n",
    "        TrialsSaveplace +=  \"/\"+ str(Modelname) +\".hyperopt\" \n",
    "        trials_step = 1  # how many additional trials to do after loading saved trials. 1 = save after every iteration\n",
    "        max_trials = 3  # initial max_trials. put something small to not have to wait\n",
    "\n",
    "        \n",
    "        try:  # try to load an already saved trials object, and increase the max\n",
    "            trials = pickle.load(open(TrialsSaveplace, \"rb\"))\n",
    "            print(\"Found saved Trials! Loading...\")\n",
    "            max_trials = len(trials.trials) + trials_step\n",
    "            print(\"Rerunning from {} trials to {} (+{}) trials\".format(len(trials.trials), max_trials, trials_step))\n",
    "        except:  # create a new trials object and start searching\n",
    "            trials = Trials()\n",
    "\n",
    "        \n",
    "        lowest_loss = fmin(TrainSpacialBoxcount_with, HyperparameterAndENCODERCLASS, algo=tpe.suggest, max_evals=max_trials, trials=trials)\n",
    "\n",
    "        print(\"Lowest achieved loss so far:\", lowest_loss)\n",
    "        \n",
    "        # save the trials object\n",
    "        with open(TrialsSaveplace, \"wb\") as f:\n",
    "            pickle.dump(trials, f)\n",
    "\n",
    "\n",
    "    HyperParameterspace = {\n",
    "        'n_epochs':hp.choice('opt.n_epochs', range(5,150,5) ),\n",
    "        'batch_size':hp.choice('opt.batch_size', [2,4,8,16,32,64,128,256,512] ),\n",
    "        'lr':hp.uniform('lr', 0.0000001 , 0.1 ),\n",
    "        'b1':hp.uniform('b1', 0.01 , 1.0 ),\n",
    "        'b2':hp.uniform('b2', 0.01 , 1.0 ),\n",
    "        'Inter1':hp.choice('Inter1', range(1,512) ),\n",
    "        'Inter2':hp.choice('Inter2', range(1,512) ),\n",
    "        'Inter3':hp.choice('Inter3', range(1,512) ),\n",
    "\n",
    "    }     \n",
    "\n",
    "    HyperparameterAndENCODERCLASS = HyperParameterspace,BoxCountEncoder\n",
    "\n",
    "    print(\"Begin HyperparameterOptimization\")\n",
    "\n",
    "    # loop indefinitely and stop whenever you like by setting MaxTrys\n",
    "    MaxTrys = 100\n",
    "    for TotalTrials in range(MaxTrys):\n",
    "        Modelname = \"SpacialBoxcountEncoder\"+\"_trialsOBJ\"\n",
    "        run_trials(HyperparameterAndENCODERCLASS, \"BoxcountEncoder\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.5.8 Validation by testing different models\n",
    "Testing against a different unseen dataset is essential to prevent the model from just memorizing the incoming data also known as overfitting. \n",
    "After choosing a saved model by its modelname, the network parameters and the the models state dictionary are loaded to initialize the model. Changing the device-string, the computation place of the model can be chosen to compare the total computation time between cpu or gpu driven networks. While testing, the model is loaded in evaluation mode which disables any adjustments of the models weights and biases.\n",
    "\n",
    "Models, which need to be tested can be chosen by appending the wanted modelname, located in the subfolder 'models', to the modelname list.\n",
    "The test will load the models sequentially to iterate while tracking the mean loss and an approximation of data throughput by processed input pictures in megapixel per second.\n",
    "To compare the cpu and gpu driven models, tests on both devices are executed.\n",
    "To measure time, set the variable verbosity to false. To render images, neural network output and for debugging code, set verbosity to true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------\n",
    "#  Testing BoxcountEncoder\n",
    "# ----------\n",
    "ModelnameList = []\n",
    "#Pretrained Networks-----------------------\n",
    "ModelnameList.append(\"Loss0.01---n_epochs_135_batch-size_4_learning-rate_0.001_beta-decay_0.671_0.362\")\n",
    "ModelnameList.append(\"Loss0.01---n_epochs_85_batch-size_512_learning-rate_0.001_beta-decay_0.681_0.876\")\n",
    "ModelnameList.append(\"Loss0.014---n_epochs_5_batch-size_128_learning-rate_0.001_beta-decay_0.501_0.945\")\n",
    "ModelnameList.append(\"Loss0.506---n_epochs_25_batch-size_512_learning-rate_0.071_beta-decay_0.26_0.248\")\n",
    "ModelnameList.append(\"Loss0.735---n_epochs_95_batch-size_4_learning-rate_0.062_beta-decay_0.311_0.194\")\n",
    "ModelnameList.append(\"Loss0.012---n_epochs_135_batch-size_4_learning-rate_0.015_beta-decay_0.808_0.762\")\n",
    "\n",
    "showitem = None\n",
    "whereTObreakIteration = 100   #at batch the test will break the testloop to continue\n",
    "\n",
    "\n",
    "#To render the network output set verbosity to True\n",
    "verbosity = False\n",
    "opt.n_cpu = 8 #for every thread of my quadcore -> adjust as you like\n",
    "\n",
    "def TestSpacialBoxcount_with(Modelname, BoxCountEncoder,showitem, device):\n",
    "    #global showitem\n",
    "    NetParametersSaveplace =FileParentPath+ \"/models/\"+ Modelname +\".netparams\"\n",
    "    BoxCountNetParameters = pickle.load(open(NetParametersSaveplace, \"rb\"))\n",
    "\n",
    "    saveplace = FileParentPath+ \"/models/\"+Modelname +\".model\"\n",
    "    \n",
    "    __, parameter = Modelname.split('---')  #extracting parameter to generate option object\n",
    "    __, __, n_epochs, __,   batch_size, __, learning_rate, __ , betadecay1, betadecay2 = parameter.split('_')\n",
    "    \n",
    "    \n",
    "    #should not be nessecary, except the changing batchsize #self, n_epochs, batch_size, img_size, channels, learning_rate, b1, b2\n",
    "    opt = OptionObject(int(n_epochs), int(batch_size), ChunkLenght, 1 , float(learning_rate), float(betadecay1), float(betadecay2))\n",
    "    \n",
    "    #device = \"cuda\"\n",
    "    #device = \"cpu\"\n",
    "    \n",
    "    #load and init the BCencoder\n",
    "    BoxCountEncoder = BoxCountEncoder(BoxCountNetParameters)\n",
    "    BoxCountEncoder.load_state_dict(torch.load(saveplace, map_location=device))\n",
    "    BoxCountEncoder.eval()   #to disable backpropagation, so don't adjust any weights and biases\n",
    "\n",
    "    #define Loss\n",
    "    pixelwise_loss = torch.nn.L1Loss()\n",
    "\n",
    "    #Init BoxcountEncoder\n",
    "    BoxCountEncoder.to(device)\n",
    "    pixelwise_loss.to(device)\n",
    "\n",
    "    # Optimizers\n",
    "    optimizer_BC = torch.optim.Adam(BoxCountEncoder.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "    if device==\"cuda\":\n",
    "        Tensor = torch.cuda.FloatTensor \n",
    "    else:\n",
    "        Tensor = torch.FloatTensor\n",
    "    \n",
    "    totaltime = 0.0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    \n",
    "    #Begin testing by evaluating the test data set\n",
    "    for  i, (images, labels_2, labels_4, labels_8, labels_16 )  in enumerate(testDataLoader):\n",
    "        if i== whereTObreakIteration:\n",
    "            print(\"reached iteration\",whereTObreakIteration, \"break loop to test next model\" )\n",
    "            break\n",
    "            \n",
    "        start = time.time()\n",
    "        \n",
    "        torch.no_grad() # for testing no gradients have to be computed\n",
    "        # Configure input/ouput variables and send it to device\n",
    "        real_imgs = Variable(images.type(Tensor))\n",
    "        real_imgs.to(device)\n",
    "        # BCR_map/Lac_map with boxsize 2\n",
    "        real_labels_2 = Variable(labels_2.type(Tensor))\n",
    "        real_labels_2.to(device)\n",
    "        # BCR_map/Lac_map with boxsize 4\n",
    "        real_labels_4 = Variable(labels_4.type(Tensor))\n",
    "        real_labels_4.to(device)\n",
    "        # BCR_map/Lac_map with boxsize 8\n",
    "        real_labels_8 = Variable(labels_8.type(Tensor))\n",
    "        real_labels_8.to(device)\n",
    "        # BCR_map/Lac_map with boxsize 16\n",
    "        real_labels_16 = Variable(labels_16.type(Tensor))\n",
    "        real_labels_16.to(device)\n",
    "\n",
    "        BCR_LAK_map_2 , BCR_LAK_map_4 , BCR_LAK_map_8 , BCR_LAK_map_16 = BoxCountEncoder(real_imgs)\n",
    "        optimizer_BC.zero_grad()\n",
    "        \n",
    "        #necessary for accessing the picture again with numpy\n",
    "        NumpyencImg2 =  BCR_LAK_map_2.cpu().detach().numpy()\n",
    "        NumpyencImg4 =  BCR_LAK_map_4.cpu().detach().numpy()\n",
    "        NumpyencImg8 =  BCR_LAK_map_8.cpu().detach().numpy()\n",
    "        NumpyencImg16 =  BCR_LAK_map_16.cpu().detach().numpy()\n",
    "\n",
    "        if verbosity:\n",
    "            #Render Pictures \n",
    "            for idx in range(opt.batch_size):\n",
    "                print(\"index within batch:\", idx)\n",
    "                showNPArrayAsImage(images[idx,0,:,:], \"Original Image\", \"gray\")\n",
    "\n",
    "                #source: [18] https://stackoverflow.com/questions/22053274/grid-of-images-in-matplotlib-with-no-padding\n",
    "                max_cols = 8\n",
    "                fig, axes = plt.subplots(nrows=2, ncols=max_cols, figsize=(16,4))\n",
    "                lablelist = [labels_2[idx,0,:,:], labels_2[idx,1,:,:], labels_4[idx,0,:,:], labels_4[idx,1,:,:], labels_8[idx,0,:,:], labels_8[idx,1,:,:], labels_16[idx,0,:,:],  labels_16[idx,1,:,:], NumpyencImg2[idx,0,:,:], NumpyencImg2[idx,1,:,:], NumpyencImg4[idx,0,:,:], NumpyencImg4[idx,1,:,:], NumpyencImg8[idx,0,:,:], NumpyencImg8[idx,1,:,:], NumpyencImg16[idx,0,:,:]  , NumpyencImg16[idx,1,:,:]]\n",
    "                #titlelist = [\"BCR2\", \"LAC2\", \"BCR4\", \"LAC4\", \"BCR8\", \"LAC8\",\"BCR16\", \"LAC16\", \"NN BCR2\", \"NN LAC2\",   ]\n",
    "                ylabellist = [\"CPU\", \"\", \"\",\"\", \"\", \"\", \"\",\"\", \"GPU\", \"\",\"\",\"\",\"\", \"\", \"\",\"\"]\n",
    "                xlabellist = [\"\", \"\", \"\",\"\", \"\", \"\",\"\",\"\",\"BCR2\" ,\"LAC2\" ,\"BCR4\" ,\"LAC4\" ,\"BCR8\" ,\"LAC8\" ,\"BCR16\" ,\"LAC16\" ]\n",
    "                for idx, image in enumerate(lablelist):\n",
    "                    row = idx // max_cols\n",
    "                    col = idx % max_cols\n",
    "                    #axes[row, col].axis(\"off\")\n",
    "                    axes[row, col].imshow(image, cmap=\"gray\", aspect=\"auto\")\n",
    "                    #axes[row, col].set_title(titlelist[idx])\n",
    "                    # label x-axis and y-axis \n",
    "                    axes[row, col].set_ylabel(ylabellist[idx]) \n",
    "                    axes[row, col].set_xlabel(ylabellist[idx]) \n",
    "\n",
    "                plt.subplots_adjust(wspace=.05, hspace=.05)\n",
    "                plt.show()\n",
    "\n",
    "                if showitem == None or showitem == \"y\" or showitem == \"Y\":\n",
    "                    showitem = input(\"press  y/Y for next item in batch  or else to continue with next batch\")\n",
    "                    if showitem == \"y\" or showitem == \"Y\":\n",
    "                        continue\n",
    "                    else:\n",
    "                        showitem = None\n",
    "                        break\n",
    "\n",
    "                    \n",
    "        end = time.time()  #cause loss calulation has nothing to do with boxcount calc time\n",
    "\n",
    "        # Scalable pixelwise loss to have    \n",
    "        BCR_LAK_map_2_loss  = pixelwise_loss(BCR_LAK_map_2, real_labels_2)\n",
    "        BCR_LAK_map_4_loss = pixelwise_loss(BCR_LAK_map_4, real_labels_4)\n",
    "        BCR_LAK_map_8_loss = pixelwise_loss(BCR_LAK_map_8, real_labels_8)\n",
    "        BCR_LAK_map_16_loss = pixelwise_loss(BCR_LAK_map_16, real_labels_16)\n",
    "        Scalefactor_2 , Scalefactor_4 , Scalefactor_8 , Scalefactor_16  =  0.25, 0.25, 0.25 , 0.25      # maybe optimiziing usage?!\n",
    "\n",
    "        BCR_LAK_loss =  Scalefactor_2 * BCR_LAK_map_2_loss + Scalefactor_4 * BCR_LAK_map_4_loss + Scalefactor_8 * BCR_LAK_map_8_loss + Scalefactor_16 * BCR_LAK_map_16_loss\n",
    "        \n",
    "        running_loss += BCR_LAK_loss.item()\n",
    "\n",
    "        BCR_LAK_loss.backward()\n",
    "        optimizer_BC.step()\n",
    "        \n",
    "        timePERbatch = end - start\n",
    "        totaltime += timePERbatch\n",
    "        \n",
    "        if verbosity: \n",
    "            print(\"[Batch %d/%d] [BC loss: %f] \"% ( i, len(testDataLoader), BCR_LAK_loss.item()))\n",
    "            print(timePERbatch, \" seconds for boxcounting 1 file with batch_size of\",opt.batch_size )\n",
    "            \n",
    "        #input(\"presskey fornext batch\")\n",
    "    mean_timePERbatch = totaltime / float(whereTObreakIteration)\n",
    "    mean_loss = running_loss/ float(whereTObreakIteration)  # cause testing will abort after 100 batchesm has to be normalized \n",
    "\n",
    "    return mean_loss, mean_timePERbatch\n",
    "\n",
    "youwanttotest = input(\"Do you want to test? Y/n\")\n",
    "\n",
    "\n",
    "scoreboard = {}\n",
    "#{'Modelname': mean_loss, timePerbatch, MegapixelPERsecond}\n",
    "\n",
    "#If cuda is avaiable, then test against both\n",
    "device = get_device()\n",
    "if device==\"cuda\":\n",
    "    devicelist = ['cpu','cuda']\n",
    "else:\n",
    "    devicelist = ['cpu']\n",
    "\n",
    "if youwanttotest == \"\" or youwanttotest == \"y\" or youwanttotest == \"Y\":\n",
    "    for device in devicelist:\n",
    "        \n",
    "        for Modelname in ModelnameList:\n",
    "            print(\"-----------begin test with new model-------------\")\n",
    "            print(\"Chosen Device is\", device)\n",
    "            print(\"Modelname: \", Modelname)\n",
    "            mean_loss,  mean_timePERbatch = TestSpacialBoxcount_with(Modelname,BoxCountEncoder,showitem, device)\n",
    "            mean_loss,  mean_timePERbatch = round(mean_loss,2),  round(mean_timePERbatch,2) \n",
    "            MegapixelPERsecond =  round( (opt.batch_size * opt.img_size**2) /(mean_timePERbatch* 1000000 ) ,2)\n",
    "            fullmodelname = device +'_'+ Modelname\n",
    "            scoreboard[fullmodelname] = [mean_loss, mean_timePERbatch, MegapixelPERsecond ]\n",
    "            print(\"This model performed with a mean loss of\", mean_loss, \"with a mean time/batch\", mean_timePERbatch, \"with a pixelthroughput of\",MegapixelPERsecond,\" Mpx/s\" )\n",
    "\n",
    "    #print(\"scoreboard: \", scoreboard)\n",
    "    for key, item in scoreboard.items():\n",
    "        print(\"Model:\",key,\" with mean_testloss of\", item[0], \" with a mean time/batch\", item[1], \"with a pixelthroughput of\", item[2] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4 Results and discussion\n",
    "\n",
    "### 4.1 Results:\n",
    "\n",
    "A spacially depending boxcounting algorithm was proposed, where a box scans in a fixed grid manner over a slice of a 3D array to count the filled boxes in comparison to the total number of boxes, named the boxcount ratio. It also counts the number of datapoints per cube to be able to calculate the spacial heterogeneity, also known as the lacunarity.\n",
    "So instead of counting boxes for the whole picture at once the picture was chunked into chunks in the range of all chosen boxsizes, to spacially characterize the input picture at different scales. \n",
    "In every chunk ranging from chosen borders in x and y, but the whole z-direction the boxcounting was executed and a boxcount ratio and lacunarity returned to ensemble a two channel scaled down array of the picture like in figure 10 demonstrated. \n",
    "\n",
    "\n",
    "![image info](https://raw.githubusercontent.com/ollimacp/spacial-boxcounting-cpu-gpu/main/0Data/generated_imgs/7_4_3700x.png)\n",
    "\n",
    "Figure 10: Generated output from the spacial boxcounting with the spacial boxcount ratio as BCR and lacunarity as LAC with their boxsizes 2, 4, 8, 16\n",
    "\n",
    "The boxcount ratio is an indicator of spacial complexity. From these boxcounts ranging over different boxsizes, the fractal dimension could be calculated, which gives any object a continuous dimensionality.\n",
    "The lacunarity is an indicator for spacial heterogeneity, so it detects defects in patterns. By changing the boxsize the lacunarity can be controlled in terms of scaling, so defects or patterns at different scales are adressed to make the lacunarity a candidate for an edge detection application, or for dimensionality reduction as a preprocessing step.\n",
    "\n",
    "The boxcount algorithm can be split up during execution into different threads handling all different boxsizes at once to gain some speed compared to single threaded performance, but consumes also more system memory. \n",
    "\n",
    "Boxcounting allows for quantitative continuous characterization of arbitrary 2D arrays for statistical analysis, spacial categorizing, similarity search and sorting purposes.\n",
    "\n",
    "Spacial boxcounting retains spacial information by returning an array of boxcount ratio and lacunaritys, where any value of this resulting array the spacial complexity or heterogeneity in a given point describes.\n",
    "\n",
    "To harness potential parallel processing power an attempt was made to translate the previous cpu driven process into a neural network. This network allows for all the processing for all boxsizes at once, so it could be faster then the sequential driven process, even with multithreading, depending on the chosen hardware.\n",
    "\n",
    "\n",
    "###  4.2 Discussion\n",
    "\n",
    "#### 4.2.1 Timebased computational efficiency  \n",
    "\n",
    "The time elapsed per processed picture with the spacial boxcount from 3.3.2 is heavily dependend on the chosen boxsize. So by increasing the minimal boxsize, the execution time per picture but also the resolution for finest pattern decreases. \n",
    "If the spacial boxcounting is executed just with one boxsize, the process takes 1-2 seconds with the boxsize 2 and just 100 to 10 milliseconds for bigger boxsizes. Beware, that the maximum boxsize can only be as big as the minimum value of the pictures resolution or depth of color.\n",
    "\n",
    "By measuring the time taken to execute and return the wanted values, the computational time efficiency can be observed. Since this demonstration uses pictures, the metric megapixels of processed, incoming data per second is used.\n",
    "A grayscale full HD video with 30 frames per second would result in  62,20 megapixel per second, which would allow for realtime video analysis or processing.\n",
    "The cpu driven multithreaded process with the standard python interpreter or the numba-jit compiler can be compared against the neural network loaded into the cpu or gpu.\n",
    "Here the intel i7-4790k cpu's performance  is compared to a nvidia gtx 1070. So execution times may vary on different systems. The time for each category was measured over 100 pictures for the boxcounting and 100 batches for the network.\n",
    "\n",
    "Note, that the neural network does never achieve a loss of zero, so the quality of the results is always lower than the original boxcount algorithm. \n",
    "\n",
    "The standard python interpreter is by far the worst, measured at a mean of 93.67 seconds per picture sized 1280 x 960 pixels with a processing speed of 0.03 megapixel per second.\n",
    "\n",
    "To keeping the code applicable to the numba-jit compiler, by isolating computational heavy tasks into conform functions and decorating the functions with \"@jit(nopython=True)\" to enable a huge gain in computational efficiency resulting in a mean of 1.46 seconds per pictures with 0.84 megapixel per second. This is a performance gain of 28 times compared to the standard python interpreter in terms of processed data over time.\n",
    "\n",
    "Training a neuronal network is computational intensive so a gpu might be needed. The models were loaded in each instance and measured slightly less performant for the neural network executed on the cpu with values ranging from 1.94 to 8.74 megapixel per second, as of on the gpu ranging from 8.74 up to 52.43 megpixel per second. This indicates, that the gpu can utilize parallel processing power, even when the data has to be transmitted from system memory to graphics memory. With the maximum performing model, the gpu would be able to process video or streams in realtime, but with loss of accuracy.\n",
    "\n",
    "The fastest model is named \"cuda_Loss0.506---n_epochs_25_batch-size_512_learning-rate_0.071_beta-decay_0.26_0.248\" with 52.43 megpixel per second on the gpu with a mean test loss of 0.53.\n",
    "\n",
    "\n",
    "#### 4.2.2 Loss comparison\n",
    "\n",
    "The most accurate model was named \"cuda_Loss0.01---n_epochs_135_batch-size_4_learning-rate_0.001_beta-decay_0.671_0.362\" with a mean test loss of 0.01 with 26.21 megapixel/second of processed images, if executed on the gpu.\n",
    "\n",
    "![image info](https://raw.githubusercontent.com/ollimacp/spacial-boxcounting-cpu-gpu/main/0Data/Document_images/Accuracy_comparison.png)\n",
    "\n",
    "Figure 11: Input picture and output from spacial boxcounting algorithm and neural network output  \n",
    "\n",
    "Figure 11 shows a particular output of an input image. The first row shows the results of the spacial boxcounting in every boxsize. The second row displays the output of the neural network. The loss of 0.01 seems little compared to the fastest model with a mean test loss of 0.53, but by comparing the network generated output against the cpu driven process reveals discrepancies. The generated output seems to have some kind of similarity, but the observed differences are indisputable. The actual neural network architecture is not optimal and accurate enough to replace the cpu driven process for faster computation at this point in time.\n",
    "To decrease the loss further, additional convolutional neural layers could be implemented, or batch normalization layers and potentially other activation functions could be utilized or just more data could be used to train the neural network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Conclusion\n",
    "\n",
    "Boxcounting is able to quantitatively characterize any kind of data in matrix form and describes spacial complexity at different scalings. The scaling is described by the boxsize and should be executed with multiple sizes to gain scale specific knowledge. The lacunarity or spacial heterogeneity can be calculated while revealing scale depend defects in homogeneous patterns.\n",
    "\n",
    "The spacial boxcounting algorithm chunks the incoming image into boxsized pieces and calculates the spacial complexity and heterogeneity  at any point in the image, enabling spacial characterization of data. The input images can be compared to another, enabling sorting in complexity or heterogeneity, similarity search or pattern defect detection.\n",
    "\n",
    "While development time of python programs is faster than low-level programming  languages, the execution time of python code is terrible. By using a high performance compiler, the computation time can be many times faster, than the standard python compiler. \n",
    "\n",
    "To gain more time based performance, a convolutional neural network with multiple outputs were used to mimic the cpu driven process and try to compute every output in one forward pass. The computation time per picture can be lowered even more, but the outputs of the neural network are not completely accurate, so decreased quality is traded for increased quantity. Further optimizing the models architecture can resolve in a model fast and accurate enough to enable realtime video or stream processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 ACKNOWLEDGMENTS AND SOURCES\n",
    "\n",
    "### Example dataset location: <https://drive.google.com/file/d/1sLc8Uk61W_4TTtmRk4x6_5cOiWq7IeOT/view?usp=sharing>\n",
    "\n",
    "### [1] Boxcounting:  <https://en.wikipedia.org/wiki/Box_counting>\n",
    "\n",
    "### [2] Lacunarity:  <https://en.wikipedia.org/wiki/Lacunarity>\n",
    "\n",
    "### [3] Numpy documentation: <https://numpy.org/doc/1.20/>\n",
    "\n",
    "### [4] TQDM  documentation: <https://tqdm.github.io/docs/tqdm/>\n",
    "\n",
    "### [5] Matplotlib  documentation: <https://matplotlib.org/3.3.3/contents.html>\n",
    "\n",
    "### [6] Pathlib  documentation: <https://docs.python.org/3/library/pathlib.html>\n",
    "\n",
    "### [7] Numba  documentation:  <https://numba.readthedocs.io/en/stable/user/jit.html>\n",
    "\n",
    "### [8] Pytorch   documentation: <https://pytorch.org/docs/stable/nn.init.html>\n",
    "\n",
    "### [9] Sci-kit learn  documentation: <https://sklearn.org/documentation.html>\n",
    "\n",
    "### [10] Hyperopt documentation: <http://hyperopt.github.io/hyperopt/>\n",
    "\n",
    "### [11] OS libary documentation:  <https://docs.python.org/3/library/os.html>\n",
    "\n",
    "### [12] Pickle documentation:  <https://docs.python.org/3/library/pickle.html>\n",
    "\n",
    "### [13] Time documentation: <https://docs.python.org/3/library/time.html>\n",
    "\n",
    "### [14] Pillow image libary: <https://pillow.readthedocs.io/en/stable/>\n",
    "\n",
    "### [15] How to install pytorch : <https://varhowto.com/install-pytorch-1-6-0/>\n",
    "\n",
    "### [16] Exception handeling: <https://stackoverflow.com/questions/14519177/python-exception-handling-line-number#20264059>\n",
    "\n",
    "### [17] Custom threading base class:  <https://stackoverflow.com/questions/6893968/how-to-get-the-return-value-from-a-thread-in-python>\n",
    "\n",
    "### [18] Display images with matplotlib:  <https://stackoverflow.com/questions/22053274/grid-of-images-in-matplotlib-with-no-padding>\n",
    "\n",
    "### [19] Sort dictionary by value: <https://stackabuse.com/how-to-sort-dictionary-by-value-in-python/>\n",
    "\n",
    "### [20] Pad numpy array with zeros:  <https://stackoverflow.com/questions/35751306/python-how-to-pad-numpy-array-with-zeros>\n",
    "\n",
    "### [21] Create custom dataset for pytorch: <https://stackoverflow.com/questions/56774582/adding-custom-labels-to-pytorch-dataloader-dataset-does-not-work-for-custom-data>\n",
    "\n",
    "### [22] Save progress during hyperoptimization: <https://github.com/hyperopt/hyperopt/issues/267>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
